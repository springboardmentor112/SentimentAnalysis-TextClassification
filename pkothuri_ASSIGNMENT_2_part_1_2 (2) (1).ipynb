{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HrLXjQW7Vin"
   },
   "source": [
    "# **PART - I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Iail1mUaPfi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amDmCe0labl_"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASMm3W-JacGQ",
    "outputId": "34a29059-1e9f-4891-a86f-6a6d2e0664d5"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pUsTM2XxacJD",
    "outputId": "ceae61db-bd67-4c24-8a6e-6c0025ed0fbe"
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "KByZGyZyacL5",
    "outputId": "319f54d1-1c9c-489f-d8a5-7f8d07ed7f48"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlfjw_gEacOq",
    "outputId": "b16c0820-5db3-436e-f40f-4bf81a63a1ef"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ry0BT1zJacRK"
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "  df[col] = pd.to_numeric(df[col], errors='coerce', downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr2__JnVSj2H",
    "outputId": "6cf2d013-f3b4-478e-eaa4-038af721268e"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "H8Y0v_maacTw",
    "outputId": "ef70ea5d-fb9b-4dcb-b716-b15fe8c47f19"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUOlIggaTaYV"
   },
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "nQ8EGR3EI5qW",
    "outputId": "44959ebd-c9e1-4eeb-fa2b-205b457ac372"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "OtLPAdxh96XO",
    "outputId": "be3c2644-58f5-4361-e8ee-e9381eb0ddee"
   },
   "outputs": [],
   "source": [
    "plt.plot(df['f1'],df['target'], alpha=0.5, color='green')\n",
    "plt.xlabel('f1')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "ZO1U6pGr96kJ",
    "outputId": "cfef51bc-183a-43ba-c27c-6ff0ab521454"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['f2'],df['target'], alpha=0.5, color='green')\n",
    "plt.xlabel('f2')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "FPFF4q2p96vB",
    "outputId": "2f04373a-b583-445b-842a-365f39442254"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['f3'],df['target'], alpha=0.5, color='green')\n",
    "plt.xlabel('f3')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnbBgFKUacWR",
    "outputId": "97b1b1f0-0b3f-4a8e-83da-59daa717276b"
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cfi3EKNvacZJ",
    "outputId": "473a57d6-b14a-4eb6-87fd-4b91544b47a3"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df= scaler.fit_transform(df)\n",
    "def normalize_df(df,col):\n",
    "  mini = df[col].min()\n",
    "  maxi = df[col].max()\n",
    "  df[col]= df[col].apply(lambda x: (x-mini)/(maxi-mini))\n",
    "  return df\n",
    "\n",
    "for col in df.columns:\n",
    "  df = normalize_df(df,col)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_df = scaler.fit_transform(df)\n",
    "# df = pd.DataFrame(scaled_df, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Qj6r21CFaccF",
    "outputId": "144caeac-6143-415d-8d88-97860929358b"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BO9IrCcaacej"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FV-BwDrZN2rM",
    "outputId": "3c2ef73c-1beb-4b05-8e2f-d6c5eec254cb"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYJQ8FgfachN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnvmZrwZacjz"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "# def xavier_init(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_uniform_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8osnBccacmZ"
   },
   "outputs": [],
   "source": [
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "# model.apply(xavier_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duViSnQJacpQ",
    "outputId": "adc986e4-652b-4271-b122-44fa8fe13ae6"
   },
   "outputs": [],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46S34LZWM4J6"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OejxxCJCacr9",
    "outputId": "5ecf130c-8a34-4e54-d02b-8f125910d5df"
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "batch_size = 32\n",
    "input_data = torch.randn(batch_size, input_size)\n",
    "print(summary(model, input_data=input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ye9VpVPyRZqO"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7DIMQ_NUad-",
    "outputId": "6c6a7959-6f9b-4721-c94b-9e727995b0d7"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qTMBkrzDjJi",
    "outputId": "01a139e7-5bab-4bec-cbda-0a5db38763a3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), \"part_1_model_75.44.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "TaHUTktSacus",
    "outputId": "e8e6c243-2aab-477e-c34a-96c280e0b986"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(epochs), train_losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "q3TFCKgDacxa",
    "outputId": "64ebd61d-2a0e-46f6-e61b-7a08da9964ef"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), val_losses)\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "Z85e5Oakyv_r",
    "outputId": "9560cee5-b30c-4c7e-a61a-b08d7fb2a5ea"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), test_losses)\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW3bsRZDewbD"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54BiS0BvjvL4",
    "outputId": "26d0c274-d2af-4a59-8822-55f7802373ce"
   },
   "outputs": [],
   "source": [
    "print(y_pred.dtype)\n",
    "print(y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYnCJ97Fs3Oi",
    "outputId": "88f881e0-4d98-4972-e728-6ba87552f8f1"
   },
   "outputs": [],
   "source": [
    "print(y_val.shape)\n",
    "print(y_val.dtype)\n",
    "print(y_pred_val.shape)\n",
    "print(y_pred_val.dtype)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "print(y_pred_val.dtype)\n",
    "print(y_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHqzamlktJoZ",
    "outputId": "17dddc43-90f4-4df6-ab4d-57fc323c418f"
   },
   "outputs": [],
   "source": [
    "print(y_test.dtype)\n",
    "print(y_pred_test.shape)\n",
    "print(y_pred_test.dtype)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(y_pred_test.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6FDrMDgac0A",
    "outputId": "dc327535-ce1b-463c-efdc-cd81cca35088"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hmbg9UbsELt",
    "outputId": "d9e779ab-f3bb-47a6-ca51-2e1651585f8e"
   },
   "outputs": [],
   "source": [
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vZCVSS7sEQD",
    "outputId": "7d480faa-63c9-47eb-a7f0-9f71b498752c"
   },
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "nNgYrS8_ehsb",
    "outputId": "dc54ca60-1b69-45fe-8fce-99b48131a66f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "YUHjZEy9eh_W",
    "outputId": "1b6dd940-af01-4b2b-87f9-97bfd1e91705"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "N51mv1iuiABF",
    "outputId": "5a1779c7-c144-468c-8006-c989bb96856b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "# plt.plot(accuracy*100, label='Training Accuracy')\n",
    "# plt.plot(accuracy_val*100, label='Validation Accuracy')\n",
    "# plt.plot(accuracy_test*100, label='Test Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training, Validation, and Test Accuracy')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "zyBi1ZiAkFjc",
    "outputId": "01dea97d-e18a-4dd4-ce85-43632b3b9036"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JxaWADyac23"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVj-yNNFV-fA"
   },
   "source": [
    "# **PART-II**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XelmJoRZH0GY"
   },
   "source": [
    "### **Dropout-0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wpsByHoNac5p",
    "outputId": "eeb650c0-baee-4fca-e7d4-fffc58b7ebc3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.1\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6xV_r4TIG7S"
   },
   "source": [
    "### **Dropout-0.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jlBKQn_8ac8F",
    "outputId": "54f5df69-e19c-46c4-a64b-fde8ac7562f4"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.2\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), \"part_2_dropout_model_74.56.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJaCGEuAIJez"
   },
   "source": [
    "### **Dropout-0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L6tilRvyac-6",
    "outputId": "8be0473b-1cd5-4f32-c6c7-6cf68a10b513"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.5\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ujk_0eYTINY4"
   },
   "source": [
    "### **Optimizer-Adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "brX7NHRDadB2",
    "outputId": "d548bfbe-b736-4705-87ed-92811556356a"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNHuuP6zIWKk"
   },
   "source": [
    "### **Optimizer-Adagrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pQs4sNPladEX",
    "outputId": "071df104-0799-4a1a-f66a-f8c17def2028"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "base_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {base_accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, base_accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), \"part_2_optimizer_model_77.19.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaEHkAxnIbjU"
   },
   "source": [
    "### **Optimizer-Adamax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NJTtxraTadG-",
    "outputId": "21c47868-3d8c-41d8-d218-ca18acd1d1e8"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGl61oB9Iez8"
   },
   "source": [
    "### **Activation Function-tanh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RCN4B68_adPF",
    "outputId": "dbfa32e1-6ce5-489e-ecf1-173891e73575"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.tanh(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYGK76FbJjvy"
   },
   "source": [
    "### **Activation Function-selu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S2cdSpnZadUL",
    "outputId": "2549ee8e-239d-4c7e-d6a0-dff54922d391"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.selu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf0yxtLiJuc9"
   },
   "source": [
    "### **Activation Function-elu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ui1tp5AcadW7",
    "outputId": "63e76ad1-fe8f-4057-8315-e20beaf21f85"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.elu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), \"part_2_ActivationFunction_model_77.19.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eU59PU0J1DE"
   },
   "source": [
    "### **Initializer-Xavir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b00wYcc4adZQ",
    "outputId": "66559ea2-e12a-4bc0-b2d7-a6d1a91860ca"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "def xavier_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "model.apply(xavier_init)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), \"part_2_Initializer_model_72.81.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBFnsakCKXMx"
   },
   "source": [
    "### **Kaiming uniform initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8SUr5nSSv6Lj",
    "outputId": "7ce9b276-d25f-4f3c-d135-9a0c97188960"
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        init.kaiming_uniform_(self.input_layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        for layer in self.hidden_layers:\n",
    "            init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        init.kaiming_uniform_(self.output_layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOE0idxNNbrw"
   },
   "source": [
    "### **Initializer-lecun_init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QSioOdh6adcJ",
    "outputId": "18d49c00-2393-4533-9a26-448510fb8c29"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "def lecun_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        fan_in = m.weight.size(1)\n",
    "        nn.init.normal_(m.weight, mean=0, std=1 / fan_in)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "model.apply(lecun_init)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Train', 'Validation','Test']\n",
    "accuracies = [accuracy, accuracy_val, accuracy_test]\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO8ua7245FWA"
   },
   "source": [
    "# **EARLY STOPPING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KoQ4vVsbadhi",
    "outputId": "d4aadce3-86ab-4f27-a188-15d5fb7e3820"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_state = None\n",
    "stop_flag = 0\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        stop_flag = 0\n",
    "    else:\n",
    "        stop_flag += 1\n",
    "        if stop_flag >= early_stopping_patience:\n",
    "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "print('Finished Training')\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"Train Accuracy\")\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Validation Accuracy\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "print(\"Test Accuracy\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Base Model', 'Current Model']\n",
    "test_accuracies = [base_accuracy_test, accuracy_test]\n",
    "plt.bar(model_names, test_accuracies)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "percentage_change = ((accuracy_test - base_accuracy_test) / base_accuracy_test) * 100\n",
    "plt.bar(model_names, [0, percentage_change], color=['blue', 'green'])\n",
    "plt.ylabel('Percentage Change in Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy Improvement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkMtOCdl63I3"
   },
   "source": [
    "# **LEARNING RATE SCHEDULER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "47aOlpPBadnH",
    "outputId": "1dc78279-ba1f-4011-e749-9dd0e47e1b86"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "    scheduler.step()\n",
    "print('Finished Training')\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Base Model', 'Current Model']\n",
    "test_accuracies = [base_accuracy_test, accuracy_test]\n",
    "plt.bar(model_names, test_accuracies)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "percentage_change = ((accuracy_test - base_accuracy_test) / base_accuracy_test) * 100\n",
    "plt.bar(model_names, [0, percentage_change], color=['blue', 'green'])\n",
    "plt.ylabel('Percentage Change in Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy Improvement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGsJZQir-IAd"
   },
   "source": [
    "# **BATCH NORMALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TdUtrzLVadpj",
    "outputId": "e5f3503f-b9f9-45f3-8331-6ff5b93ebb70"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn_input = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]) for i in range(len(hidden_sizes) - 1)\n",
    "        ])\n",
    "        self.bn_hidden = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_sizes[i + 1]) for i in range(len(hidden_sizes) - 1)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = self.bn_input(x)\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.bn_hidden[i](x)\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Base Model', 'Current Model']\n",
    "test_accuracies = [base_accuracy_test, accuracy_test]\n",
    "plt.bar(model_names, test_accuracies)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "percentage_change = ((accuracy_test - base_accuracy_test) / base_accuracy_test) * 100\n",
    "plt.bar(model_names, [0, percentage_change], color=['blue', 'green'])\n",
    "plt.ylabel('Percentage Change in Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy Improvement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl8kFgdCYg-t"
   },
   "source": [
    "# **GRADIENT CLIPPING**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8888uXnCadxz",
    "outputId": "a77f4b45-9957-495a-cec0-29ed6642828b"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "torch.manual_seed(42)\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "model = NN_Model(input_size, hidden_sizes, output_size,dropout_prob)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "validation_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "y_train = y_train.long()\n",
    "y_val = y_val.long()\n",
    "y_test = y_test.long()\n",
    "print(\"Unique values in y_train:\", torch.unique(y_train))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "test_losses=[]\n",
    "max_gradient_norm = 1.0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_loss += val_loss.item()\n",
    "    avg_val_loss = val_loss / len(validationloader)\n",
    "    train_losses.append(val_loss.detach().numpy())\n",
    "    val_losses.append(avg_val_loss.detach().numpy())\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        test_loss = criterion(y_pred_test, y_test)\n",
    "        test_loss += test_loss.item()\n",
    "    avg_test_loss = test_loss/len(testloader)\n",
    "    test_losses.append(avg_test_loss.detach().numpy())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, Test Loss: {avg_test_loss}')\n",
    "print('Finished Training')\n",
    "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
    "y_pred_val = np.argmax(y_pred_val.detach().numpy(), axis=1)\n",
    "y_pred_test=np.argmax(y_pred_test.detach().numpy(), axis=1)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred, average='binary')\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "print(f\"Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_val:.2f}\")\n",
    "print(f\"Recall: {recall_val:.2f}\")\n",
    "print(f\"F1 Score: {f1_val:.2f}\")\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall: {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Base Model', 'Current Model']\n",
    "test_accuracies = [base_accuracy_test, accuracy_test]\n",
    "plt.bar(model_names, test_accuracies)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "percentage_change = ((accuracy_test - base_accuracy_test) / base_accuracy_test) * 100\n",
    "plt.bar(model_names, [0, percentage_change], color=['blue', 'green'])\n",
    "plt.ylabel('Percentage Change in Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy Improvement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efWY_3gnbFSl"
   },
   "source": [
    "# **K-FOLD, ENSEMBLE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Hb2Y3rEvad3L",
    "outputId": "b186d427-01d4-4e10-ae1c-31c6f5e2903f"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "torch.manual_seed(42)\n",
    "class Improved_NN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size,dropout_prob):\n",
    "        super(Improved_NN_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes) - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, dtype=torch.float)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "input_size = 7\n",
    "hidden_sizes = [128, 128, 128]\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "num_models = 5\n",
    "ensemble_models = []\n",
    "kf = KFold(n_splits=num_models)\n",
    "kf.get_n_splits(X)\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(X)):\n",
    "    K_X_train, K_X_test = X.iloc[train_indices].to_numpy(), X.iloc[test_indices].to_numpy()\n",
    "    K_y_train, K_y_test = y.iloc[train_indices].to_numpy(), y.iloc[test_indices].to_numpy()\n",
    "    K_train_dataset = TensorDataset(torch.FloatTensor(K_X_train), torch.LongTensor(K_y_train))\n",
    "    K_test_dataset = TensorDataset(torch.FloatTensor(K_X_test), torch.LongTensor(K_y_test))\n",
    "    K_trainloader = DataLoader(K_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    K_testloader = DataLoader(K_test_dataset, batch_size=batch_size)\n",
    "    # K_train_dataset = TensorDataset(K_X_train, K_y_train)\n",
    "    # K_test_dataset = TensorDataset(K_X_test, K_y_test)\n",
    "    # K_trainloader = DataLoader(K_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # K_testloader = DataLoader(K_test_dataset, batch_size=batch_size)\n",
    "    model = NN_Model(input_size, hidden_sizes, output_size, dropout_prob)\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 100\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(K_trainloader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            K_y_pred = model.forward(torch.FloatTensor(K_X_train))\n",
    "            loss = criterion(K_y_pred, torch.LongTensor(K_y_train))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(K_testloader, 0):\n",
    "                K_y_pred_test = model.forward(torch.FloatTensor(K_X_test))\n",
    "                test_loss = criterion(K_y_pred_test, torch.LongTensor(K_y_test))\n",
    "                test_loss += test_loss.item()\n",
    "\n",
    "        print(f'Fold {fold+1}, Epoch {epoch+1}/{epochs}, Training Loss: {running_loss}, Test Loss: {test_loss}')\n",
    "    ensemble_models.append(model)\n",
    "ensemble_predictions = []\n",
    "for model in ensemble_models:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model.forward(X_test)\n",
    "        ensemble_predictions.append(y_pred_test.numpy())\n",
    "final_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "y_pred_test = np.argmax(final_predictions, axis=1)\n",
    "accuracy_test_improved = accuracy_score(y_test, y_pred_test)\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average='binary')\n",
    "print(f\"Ensemble Test Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Ensemble Test Precision: {precision_test:.2f}\")\n",
    "print(f\"Ensemble Test Recall: {recall_test:.2f}\")\n",
    "print(f\"Ensemble Test F1 Score: {f1_test:.2f}\")\n",
    "plt.figure(figsize=(3, 3))\n",
    "model_names = ['Base Model', 'Current Model']\n",
    "test_accuracies = [base_accuracy_test, accuracy_test]\n",
    "plt.bar(model_names, test_accuracies)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Comparison of Test Accuracy')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "# percentage_change = ((accuracy_test - base_accuracy_test) / base_accuracy_test) * 100\n",
    "# plt.bar(model_names, [0, percentage_change], color=['blue', 'green'])\n",
    "# plt.ylabel('Percentage Change in Test Accuracy')\n",
    "# plt.title('Comparison of Test Accuracy Improvement')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdvI3myqR6J6"
   },
   "source": [
    "# **PART-III**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2jtVtLWad_D",
    "outputId": "7a820867-385f-4458-ff16-2dfbc79090ab"
   },
   "outputs": [],
   "source": [
    "!unzip cnn_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ha4AYMDHaeB4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lnDrKtCaeEV"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "from pickle import loads\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.data = self.load_data()\n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            for filename in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, filename)\n",
    "                data.append((img_path, class_name))\n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_index = self.classes.index(label)\n",
    "        label_tensor = torch.tensor(label_index, dtype=torch.long)\n",
    "        return image, label_tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    # transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "folder = 'cnn_dataset'\n",
    "dataset = LoadDataset(root_dir=folder, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "kXW_r3J9aeMl",
    "outputId": "5e41a4e4-92af-4743-c9b4-cab474f339bb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "images, labels = next(iter(dataloader))\n",
    "def image_show(img, title, ax):\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        index = i * 3 + j\n",
    "        image_show(images[index], title=f\"Label: {labels[index]}\", ax=axes[i, j])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "zRoN-d2AaePW",
    "outputId": "fa49f5df-ed3f-4a91-dced-2782b762db11"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "def img_show(img, title):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "grid = torchvision.utils.make_grid(images, nrow=8, padding=2)\n",
    "img_show(grid, title=\"Batch of Images\")\n",
    "print(\"Labels:\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaI_XWNWaeR9",
    "outputId": "ee2a5475-45cf-49ea-d048-e34e6731f01d"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class_distribution = defaultdict(int)\n",
    "total_samples = len(dataset)\n",
    "for _, label in dataset:\n",
    "    class_distribution[label] += 1\n",
    "print(\"Class distribution:\")\n",
    "# for class_name, count in class_distribution.items():\n",
    "#     print(f\"{class_name}: {count} samples\")\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(f\"Number of samples: {total_samples}\")\n",
    "print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "average_samples_per_class = total_samples / len(dataset.classes)\n",
    "print(f\"Average samples per class: {average_samples_per_class:.2f}\")\n",
    "max_class = max(class_distribution, key=class_distribution.get)\n",
    "min_class = min(class_distribution, key=class_distribution.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxbNlkCxaeUd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=0.8, random_state=42)\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExYltJhI3zYC"
   },
   "outputs": [],
   "source": [
    "test_dataset, remaining_test_dataset = train_test_split(test_dataset, test_size=0.5, random_state=42)\n",
    "batch_size = 32\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(remaining_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "BhR3gr4HaeWr",
    "outputId": "fbfab7da-a294-4a49-bd0b-b87cfa265120"
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = next(iter(train_dataloader))\n",
    "print(\"BATCH OF TRAIN IMAGES\")\n",
    "def train_image_show(img, title, ax):\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        index = i * 3 + j\n",
    "        train_image_show(images[index], title=f\"Label: {labels[index]}\", ax=axes[i, j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "pC_mLmMTaeai",
    "outputId": "5352ce97-9c34-44e4-8114-e9eef969b0fe"
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = next(iter(test_dataloader))\n",
    "print(\"BATCH OF TEST IMAGES\")\n",
    "def test_image_show(img, title, ax):\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        index = i * 3 + j\n",
    "        test_image_show(images[index], title=f\"Label: {labels[index]}\", ax=axes[i, j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqqUxY8JaedT",
    "outputId": "0fc1e868-f435-47dc-81f6-6d73c1bcfed8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score\n",
    "import time\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 3 * 3, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, len(dataset.classes))\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(self.relu4(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "for epoch in range(num_epochs):\n",
    "  start_time = time.time()\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "  correct = 0\n",
    "  total_samples = 0\n",
    "\n",
    "  for images, labels in train_dataloader:\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      total_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total_samples += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  train_accuracy = correct / total_samples\n",
    "  average_loss = total_loss / len(train_dataloader)\n",
    "  end_time = time.time()\n",
    "  training_time = end_time - start_time\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  val_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in val_dataloader:\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_loss += loss.item()\n",
    "  val_accuracy = correct / total\n",
    "  val_loss /= len(val_dataloader)\n",
    "\n",
    "\n",
    "  print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "  print(f\"Accuracy on the validation set: {val_accuracy * 100:.2f}%\")\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  test_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_dataloader:\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          loss = criterion(outputs, labels)\n",
    "          test_loss += loss.item()\n",
    "  test_accuracy = correct / total\n",
    "  test_loss /= len(test_dataloader)\n",
    "  print(f\"Accuracy on the test set: {test_accuracy * 100:.2f}%\")\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  train_losses.append(average_loss)\n",
    "  val_losses.append(val_loss)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "print(f\"Training Time: {training_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cdd6aK7Xocy_",
    "outputId": "7ed9cf61-7f3c-47c9-e71c-5bfd3afeef06"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "for i in range(len(dataset.classes)):\n",
    "    class_labels = np.array(all_labels) == i\n",
    "    class_probabilities = np.array(all_predictions)[:, None]\n",
    "    fpr, tpr, _ = roc_curve(class_labels, class_probabilities[:, 0])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fpr_list.append(fpr)\n",
    "    tpr_list.append(tpr)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i in range(len(dataset.classes)):\n",
    "    plt.plot(fpr_list[i], tpr_list[i], label=f' (Class {i})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJ-4Ua6RpA-l",
    "outputId": "4c6aa866-07a5-4ced-ec22-e9d3eeeee867"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "AQkVNrJnm4_B",
    "outputId": "fee2537c-5862-4a9c-9403-25b90ef5191f"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
    "axs[0].plot(range(num_epochs), train_accuracies, label='Training Accuracy')\n",
    "axs[0].plot(range(num_epochs), val_accuracies, label='Validation Accuracy')\n",
    "axs[0].plot(range(num_epochs), test_accuracies, label='Test Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_title('Training, Validation, and Test Accuracy Curves')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "\n",
    "axs[1].plot(range(num_epochs), train_losses, label='Training Loss')\n",
    "axs[1].plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "axs[1].plot(range(num_epochs), test_losses, label='Test Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_title('Training, Validation, and Test Loss Curves')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxt5euTNTMeU",
    "outputId": "dd66e300-65e3-4f06-d4a4-059cde6046c7"
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkBdBXWFXqxb",
    "outputId": "3d677a42-f5a6-4173-a3dc-c2057a434f39"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r68FxZZaeio"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Part_03_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgIKmjdQwVbZ",
    "outputId": "c336ce7f-5bcf-4615-c5e7-8e35367bb584"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 3 * 3, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, len(dataset.classes))\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(self.relu4(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "step_size = 2\n",
    "gamma = 0.5\n",
    "scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "num_epochs = 5\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "for epoch in range(num_epochs):\n",
    "  start_time = time.time()\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "  correct = 0\n",
    "  total_samples = 0\n",
    "\n",
    "  for images, labels in train_dataloader:\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      total_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total_samples += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  train_accuracy = correct / total_samples\n",
    "  average_loss = total_loss / len(train_dataloader)\n",
    "  end_time = time.time()\n",
    "  training_time = end_time - start_time\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  val_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in val_dataloader:\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_loss += loss.item()\n",
    "  val_accuracy = correct / total\n",
    "  val_loss /= len(val_dataloader)\n",
    "  scheduler.step()\n",
    "\n",
    "  print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "  print(f\"Accuracy on the validation set: {val_accuracy * 100:.2f}%\")\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  test_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_dataloader:\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          loss = criterion(outputs, labels)\n",
    "          test_loss += loss.item()\n",
    "  test_accuracy = correct / total\n",
    "  test_loss /= len(test_dataloader)\n",
    "  print(f\"Accuracy on the test set: {test_accuracy * 100:.2f}%\")\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  train_losses.append(average_loss)\n",
    "  val_losses.append(val_loss)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "print(f\"Training Time: {training_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42BOxFdwiZSA"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Part_03_LR.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z6ZinANdp_UB",
    "outputId": "c8dfe404-0d62-4c73-a926-912e132b06ea"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "for i in range(len(dataset.classes)):\n",
    "    class_labels = np.array(all_labels) == i\n",
    "    class_probabilities = np.array(all_predictions)[:, None]\n",
    "    fpr, tpr, _ = roc_curve(class_labels, class_probabilities[:, 0])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fpr_list.append(fpr)\n",
    "    tpr_list.append(tpr)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i in range(len(dataset.classes)):\n",
    "    plt.plot(fpr_list[i], tpr_list[i], label=f' (Class {i})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jgFCp3Lxhvj",
    "outputId": "caefdc2f-5652-415b-e154-5e55db8833af"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "W2s9z5Nex6EX",
    "outputId": "cdb0d3c4-3c56-4aa1-add1-03040b0b89e7"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
    "axs[0].plot(range(num_epochs), train_accuracies, label='Training Accuracy')\n",
    "axs[0].plot(range(num_epochs), val_accuracies, label='Validation Accuracy')\n",
    "axs[0].plot(range(num_epochs), test_accuracies, label='Test Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_title('Training, Validation, and Test Accuracy Curves')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "\n",
    "axs[1].plot(range(num_epochs), train_losses, label='Training Loss')\n",
    "axs[1].plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "axs[1].plot(range(num_epochs), test_losses, label='Test Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_title('Training, Validation, and Test Loss Curves')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggMjIT0NyG9v",
    "outputId": "87721f50-447a-4c20-bbbc-d3c0ec699f0e"
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxsvjXfFLVb5"
   },
   "source": [
    "# **VGG11 IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwUn9De-LTrC",
    "outputId": "b9990abe-fdf9-4294-b264-e55cf291af8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]             640\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-5        [-1, 128, 112, 112]               0\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "              ReLU-8          [-1, 256, 56, 56]               0\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-10          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 256, 28, 28]               0\n",
      "           Conv2d-12          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-13          [-1, 512, 28, 28]               0\n",
      "           Conv2d-14          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-15          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-16          [-1, 512, 14, 14]               0\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-18          [-1, 512, 14, 14]               0\n",
      "           Conv2d-19          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-20          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-21            [-1, 512, 7, 7]               0\n",
      "           Linear-22                 [-1, 4096]     102,764,544\n",
      "             ReLU-23                 [-1, 4096]               0\n",
      "           Linear-24                 [-1, 4096]      16,781,312\n",
      "             ReLU-25                 [-1, 4096]               0\n",
      "           Linear-26                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 132,862,184\n",
      "Trainable params: 132,862,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 125.12\n",
      "Params size (MB): 506.83\n",
      "Estimated Total Size (MB): 632.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG11(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=1000):\n",
    "        super(VGG11, self).__init__()\n",
    "        self.features = self._make_layers(in_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layers(self, in_channels):\n",
    "        layers = []\n",
    "        cfg = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, v, kernel_size=3, padding=1),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "model = VGG11(in_channels=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "from torchsummary import summary\n",
    "summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5n2781H8SvVu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the data directory and transformations\n",
    "data_dir = 'C:/Users/jcysu/Downloads/cnn_dataset/cnn_dataset/'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "from sklearn.model_selection import train_test_split\n",
    "vgg_train_dataset, vgg_test_dataset = train_test_split(dataset, train_size=0.8, random_state=42)\n",
    "batch_size = 32\n",
    "vgg_train_dataloader = DataLoader(vgg_train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset, validation_dataset = train_test_split(vgg_test_dataset, test_size=0.5, random_state=42)\n",
    "vgg_test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "vgg_validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "5TBWA4IALTvD",
    "outputId": "af90a0ae-39f8-4fb6-f0bc-34ec38bc2abc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "model = VGG11(in_channels=1, num_classes=36)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "fpr_list_epoch = []\n",
    "tpr_list_epoch = []\n",
    "roc_auc_list_epoch = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in vgg_train_dataloader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(vgg_train_dataloader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in vgg_validation_dataloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(val_loss / len(vgg_validation_dataloader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    test_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in vgg_test_dataloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    test_losses.append(test_loss / len(vgg_test_dataloader))\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "          f'Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%, '\n",
    "          f'Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    fpr_list = []\n",
    "    tpr_list = []\n",
    "    roc_auc_list = []\n",
    "\n",
    "#     for i in range(36):\n",
    "    for i in range(len(dataset.classes)):\n",
    "        class_labels = np.array(all_labels) == i\n",
    "        class_probabilities = np.array(all_predictions)[:, None]\n",
    "        fpr, tpr, _ = roc_curve(class_labels, class_probabilities[:, 0])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        fpr_list.append(fpr)\n",
    "        tpr_list.append(tpr)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "        \n",
    "#         class_labels = np.array(all_labels) == i\n",
    "#         class_probabilities = torch.nn.functional.softmax(outputs, dim=1)[:, i].cpu().numpy()\n",
    "#         fpr, tpr, _ = roc_curve(class_labels, class_probabilities)\n",
    "#         roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#         fpr_list.append(fpr)\n",
    "#         tpr_list.append(tpr)\n",
    "#         roc_auc_list.append(roc_auc)\n",
    "\n",
    "    fpr_list_epoch.append(fpr_list)\n",
    "    tpr_list_epoch.append(tpr_list)\n",
    "    roc_auc_list_epoch.append(roc_auc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR95xQ4xLTyb"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(36), yticklabels=range(36))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77oNAWSrLT0l"
   },
   "outputs": [],
   "source": [
    "print(f'Final Training Loss: {train_losses[-1]:.4f}, Final Training Accuracy: {train_accuracies[-1] * 100:.2f}%, '\n",
    "      f'Final Validation Loss: {val_losses[-1]:.4f}, Final Validation Accuracy: {val_accuracies[-1] * 100:.2f}%, '\n",
    "      f'Final Test Loss: {test_losses[-1]:.4f}, Final Test Accuracy: {test_accuracies[-1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyDxTRUvLT4K"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(num_classes):\n",
    "    mean_fpr = np.mean([fpr_list_epoch[e][i] for e in range(num_epochs)], axis=0)\n",
    "    mean_tpr = np.mean([tpr_list_epoch[e][i] for e in range(num_epochs)], axis=0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Label {i} (AUC = {mean_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3APgWsN5LUHx"
   },
   "outputs": [],
   "source": [
    "epochs_range = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.plot(epochs_range, test_accuracies, label='Test Accuracy', marker='o')\n",
    "\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY4xU_5hLULK"
   },
   "outputs": [],
   "source": [
    "epochs_range = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss', marker='o')\n",
    "plt.plot(epochs_range, test_losses, label='Test Loss', marker='o')\n",
    "\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DK4SrV0rLUN4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy-4vp69LURa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVq9G8ZFLUUV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7xRGwa_LUXZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
