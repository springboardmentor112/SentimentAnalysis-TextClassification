{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215b52d1-8988-400f-8998-2de746d5f286",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## IMPORT LIABRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a687fc43-2dce-442b-a72d-a8444a9995a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0e14a9f-bd1b-45c0-bda4-9d152235d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: emoji in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: demoji in c:\\users\\ambuj\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Collecting clean-text\n",
      "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "     ---------------------------------------- 0.0/175.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/175.4 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/175.4 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/175.4 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 20.5/175.4 kB 108.9 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 20.5/175.4 kB 108.9 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 20.5/175.4 kB 108.9 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 51.2/175.4 kB 174.3 kB/s eta 0:00:01\n",
      "     ---------- -------------------------- 51.2/175.4 kB 174.3 kB/s eta 0:00:01\n",
      "     ----------------- ------------------- 81.9/175.4 kB 199.1 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 102.4/175.4 kB 245.8 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 102.4/175.4 kB 245.8 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 102.4/175.4 kB 245.8 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 102.4/175.4 kB 245.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 175.4/175.4 kB 285.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy<7.0,>=6.0->clean-text)\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
      "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.4/54.4 kB 940.3 kB/s eta 0:00:00\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171058 sha256=043390e71f814fb02e61cb2a5758a4c0d12ef4a65a0720fbb68fce18d7bbb3e9\n",
      "  Stored in directory: c:\\users\\ambuj\\appdata\\local\\pip\\cache\\wheels\\bd\\22\\e5\\b69726d5e1a19795ecd3b3e7464b16c0f1d019aa94ff1c8578\n",
      "Successfully built emoji\n",
      "Installing collected packages: wcwidth, emoji, ftfy, clean-text\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: emoji\n",
      "    Found existing installation: emoji 2.11.0\n",
      "    Uninstalling emoji-2.11.0:\n",
      "      Successfully uninstalled emoji-2.11.0\n",
      "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.0 wcwidth-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install emoji\n",
    "!pip install demoji\n",
    "!pip install clean-text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592eeefe-0dac-4a71-99a0-2e3d25fdb1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AMBUJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AMBUJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AMBUJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AMBUJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00760eb-f5a2-40c3-a44a-5f4fbbefc54e",
   "metadata": {},
   "source": [
    "## IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e105a22c-d46e-41f3-92b2-de476feea62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fbe352-101c-44bf-80e9-36bd5c249255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               reviewId       userName  \\\n",
      "0  0197c118-5c6f-4a7b-894c-970023d1a350        Mar Zur   \n",
      "1  94868fb5-a21d-4ef9-ab85-81b2ed3d0785   Devin Rivera   \n",
      "2  825da34e-f65d-4ef3-991d-02d5291820d6  Heidi Kinsley   \n",
      "3  a49c2875-651a-4c33-b79c-5813780d659e  Daniel Keller   \n",
      "4  9482c75e-2e63-46ab-8c94-47273dd6a829  A Google user   \n",
      "\n",
      "                                           userImage  \\\n",
      "0  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "3  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
      "\n",
      "                                             content  thumbsUpCount  \\\n",
      "0  I have the same recurring tasks to do every da...             11   \n",
      "1  Instead of shopping around, I downloaded Any.d...              8   \n",
      "2  Why does every once in a while... out of the b...              6   \n",
      "3  Terrible Update! This app used to be perfect f...              5   \n",
      "4  This app is deceivingly terrible. There are so...             20   \n",
      "\n",
      "  reviewCreatedVersion                at  \\\n",
      "0             4.16.6.2  22-07-2020 13:13   \n",
      "1                  NaN  08-12-2020 06:24   \n",
      "2             5.11.1.2  09-07-2021 13:51   \n",
      "3                  NaN  16-11-2020 01:50   \n",
      "4             4.14.0.4  31-01-2019 16:19   \n",
      "\n",
      "                                        replyContent         repliedAt  \\\n",
      "0  Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
      "1  We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
      "2  Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
      "3  Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
      "4  Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
      "\n",
      "  appVersion      sortOrder      appId  \n",
      "0   4.16.6.2  most_relevant  com.anydo  \n",
      "1        NaN  most_relevant  com.anydo  \n",
      "2   5.11.1.2  most_relevant  com.anydo  \n",
      "3        NaN  most_relevant  com.anydo  \n",
      "4   4.14.0.4  most_relevant  com.anydo  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec746d5-b502-4dfc-ab0b-6aeeb028cdba",
   "metadata": {},
   "source": [
    "## CONVERTING DATASETS IN LOWER CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbf8d46-bf45-4c04-a718-bd8752623971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516f52c-2124-4c82-b5d4-fd7e98778f6d",
   "metadata": {},
   "source": [
    "## REMOVE LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7c3198-b2cd-48dd-a257-39cc28e41d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\" \n",
    "url_pattern = r\"http[s]?://\\S+\"\n",
    "text = re.sub(url_pattern, \"\", text)\n",
    "html_link_pattern = r\"<a href=\\\".*?\\\">.*?</a>\"\n",
    "text = re.sub(html_link_pattern, \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182526d-448e-46f0-a249-4fd2f52be131",
   "metadata": {},
   "source": [
    "## REMOVE NEXT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5d30a5-6c39-47c5-95a3-5391c106c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271aa5b4-8fd9-4c96-a973-5f0999601bc9",
   "metadata": {},
   "source": [
    "## WORDS CONTAINING NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c7f330-05f6-4b42-8357-9e9825195313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_words_with_numbers(text):\n",
    "    \n",
    "    pattern = r'\\b(?:\\w*\\d\\w*|\\d+)\\b'\n",
    "    \n",
    "    return re.sub(pattern, '', text)\n",
    "cleaned_text = remove_words_with_numbers(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88eac8-ef9d-41c4-84da-6810cc3e54ac",
   "metadata": {},
   "source": [
    "## Remove Extra Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b57b5cf-12ca-44de-95a7-13d154ff990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.strip().str.replace(r'[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b981326-7535-4952-a36f-6a6cf8893174",
   "metadata": {},
   "source": [
    "## Remove special character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b42a0ef0-7a45-4eda-ae5c-162ad151198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].astype(str)\n",
    "df['content']=df['content'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140353a-54fe-4a96-85cb-d0827a490f30",
   "metadata": {},
   "source": [
    "## Remove stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88cbc5f5-2652-439c-ae99-ad2736b28f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa20ea2-768f-46d2-a2f5-118bd98acd6e",
   "metadata": {},
   "source": [
    "## Remove Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10fb8857-499a-43ab-bc68-039c7d9d260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   reviewId               userName  \\\n",
      "0      0197c118-5c6f-4a7b-894c-970023d1a350                Mar Zur   \n",
      "1      94868fb5-a21d-4ef9-ab85-81b2ed3d0785           Devin Rivera   \n",
      "2      825da34e-f65d-4ef3-991d-02d5291820d6          Heidi Kinsley   \n",
      "3      a49c2875-651a-4c33-b79c-5813780d659e          Daniel Keller   \n",
      "4      9482c75e-2e63-46ab-8c94-47273dd6a829          A Google user   \n",
      "...                                     ...                    ...   \n",
      "16782  e9cebff8-82ad-4191-b196-127a65e9036d  Alexandra Grafwallner   \n",
      "16783  ab74c21c-3587-4393-a53d-4cb55f3e3c9b          Ljubica Pejic   \n",
      "16784  0062b15d-6e4d-4f0a-9ea6-ef9b9420d923         Kamiyah Dorsey   \n",
      "16785  85318bf2-7ca0-4d5e-8cb2-f0f18c813e4d         Keturah Pender   \n",
      "16786  8e2deadd-1a6a-4817-89dc-4bd9a198332c    Bhagwan Singh Virik   \n",
      "\n",
      "                                               userImage  \\\n",
      "0      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "1      https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "3      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "4      https://play-lh.googleusercontent.com/EGemoI2N...   \n",
      "...                                                  ...   \n",
      "16782  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "16783  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "16784  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "16785  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "16786  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                                 content  thumbsUpCount  \\\n",
      "0      i have the same recurring task to do every day...             11   \n",
      "1      instead of shopping around , i downloaded any....              8   \n",
      "2      why doe every once in a while ... out of the b...              6   \n",
      "3      terrible update ! this app used to be perfect ...              5   \n",
      "4      this app is deceivingly terrible . there are s...             20   \n",
      "...                                                  ...            ...   \n",
      "16782                                      excellent app              0   \n",
      "16783  i love it . easy to use . make my life organiz...              9   \n",
      "16784  i love how i could make plan and check the app...              0   \n",
      "16785                        exactly what i needed ! ! !              0   \n",
      "16786                                         very good               0   \n",
      "\n",
      "      reviewCreatedVersion                at  \\\n",
      "0                 4.16.6.2  22-07-2020 13:13   \n",
      "1                      NaN  08-12-2020 06:24   \n",
      "2                 5.11.1.2  09-07-2021 13:51   \n",
      "3                      NaN  16-11-2020 01:50   \n",
      "4                 4.14.0.4  31-01-2019 16:19   \n",
      "...                    ...               ...   \n",
      "16782                6.1.4  05-07-2023 02:08   \n",
      "16783                6.1.4  29-06-2023 15:27   \n",
      "16784                6.1.3  28-06-2023 01:04   \n",
      "16785                6.1.3  23-06-2023 13:14   \n",
      "16786                6.1.3  21-06-2023 03:16   \n",
      "\n",
      "                                            replyContent         repliedAt  \\\n",
      "0      Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
      "1      We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
      "2      Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
      "3      Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
      "4      Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
      "...                                                  ...               ...   \n",
      "16782                                                NaN               NaN   \n",
      "16783                                                NaN               NaN   \n",
      "16784                                                NaN               NaN   \n",
      "16785                                                NaN               NaN   \n",
      "16786                                                NaN               NaN   \n",
      "\n",
      "      appVersion      sortOrder              appId  \n",
      "0       4.16.6.2  most_relevant          com.anydo  \n",
      "1            NaN  most_relevant          com.anydo  \n",
      "2       5.11.1.2  most_relevant          com.anydo  \n",
      "3            NaN  most_relevant          com.anydo  \n",
      "4       4.14.0.4  most_relevant          com.anydo  \n",
      "...          ...            ...                ...  \n",
      "16782      6.1.4         newest  com.appxy.planner  \n",
      "16783      6.1.4         newest  com.appxy.planner  \n",
      "16784      6.1.3         newest  com.appxy.planner  \n",
      "16785      6.1.3         newest  com.appxy.planner  \n",
      "16786      6.1.3         newest  com.appxy.planner  \n",
      "\n",
      "[16787 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import demoji\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove emojis from text\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, '')\n",
    "\n",
    "# Remove emojis from the 'content' column\n",
    "df['content'] = df['content'].apply(remove_emojis)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc189518-7136-4a2f-8a25-fd116bc547e9",
   "metadata": {},
   "source": [
    "## LEMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8587212-b585-42cf-90e0-1b074699444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   reviewId               userName  \\\n",
      "0      0197c118-5c6f-4a7b-894c-970023d1a350                Mar Zur   \n",
      "1      94868fb5-a21d-4ef9-ab85-81b2ed3d0785           Devin Rivera   \n",
      "2      825da34e-f65d-4ef3-991d-02d5291820d6          Heidi Kinsley   \n",
      "3      a49c2875-651a-4c33-b79c-5813780d659e          Daniel Keller   \n",
      "4      9482c75e-2e63-46ab-8c94-47273dd6a829          A Google user   \n",
      "...                                     ...                    ...   \n",
      "16782  e9cebff8-82ad-4191-b196-127a65e9036d  Alexandra Grafwallner   \n",
      "16783  ab74c21c-3587-4393-a53d-4cb55f3e3c9b          Ljubica Pejic   \n",
      "16784  0062b15d-6e4d-4f0a-9ea6-ef9b9420d923         Kamiyah Dorsey   \n",
      "16785  85318bf2-7ca0-4d5e-8cb2-f0f18c813e4d         Keturah Pender   \n",
      "16786  8e2deadd-1a6a-4817-89dc-4bd9a198332c    Bhagwan Singh Virik   \n",
      "\n",
      "                                               userImage  \\\n",
      "0      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "1      https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "3      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "4      https://play-lh.googleusercontent.com/EGemoI2N...   \n",
      "...                                                  ...   \n",
      "16782  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "16783  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "16784  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "16785  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "16786  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                                 content  thumbsUpCount  \\\n",
      "0      i have the same recurring task to do every day...             11   \n",
      "1      instead of shopping around , i downloaded any....              8   \n",
      "2      why doe every once in a while ... out of the b...              6   \n",
      "3      terrible update ! this app used to be perfect ...              5   \n",
      "4      this app is deceivingly terrible . there are s...             20   \n",
      "...                                                  ...            ...   \n",
      "16782                                      excellent app              0   \n",
      "16783  i love it . easy to use . make my life organiz...              9   \n",
      "16784  i love how i could make plan and check the app...              0   \n",
      "16785                        exactly what i needed ! ! !              0   \n",
      "16786                                          very good              0   \n",
      "\n",
      "      reviewCreatedVersion                at  \\\n",
      "0                 4.16.6.2  22-07-2020 13:13   \n",
      "1                      NaN  08-12-2020 06:24   \n",
      "2                 5.11.1.2  09-07-2021 13:51   \n",
      "3                      NaN  16-11-2020 01:50   \n",
      "4                 4.14.0.4  31-01-2019 16:19   \n",
      "...                    ...               ...   \n",
      "16782                6.1.4  05-07-2023 02:08   \n",
      "16783                6.1.4  29-06-2023 15:27   \n",
      "16784                6.1.3  28-06-2023 01:04   \n",
      "16785                6.1.3  23-06-2023 13:14   \n",
      "16786                6.1.3  21-06-2023 03:16   \n",
      "\n",
      "                                            replyContent         repliedAt  \\\n",
      "0      Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
      "1      We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
      "2      Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
      "3      Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
      "4      Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
      "...                                                  ...               ...   \n",
      "16782                                                NaN               NaN   \n",
      "16783                                                NaN               NaN   \n",
      "16784                                                NaN               NaN   \n",
      "16785                                                NaN               NaN   \n",
      "16786                                                NaN               NaN   \n",
      "\n",
      "      appVersion      sortOrder              appId  \n",
      "0       4.16.6.2  most_relevant          com.anydo  \n",
      "1            NaN  most_relevant          com.anydo  \n",
      "2       5.11.1.2  most_relevant          com.anydo  \n",
      "3            NaN  most_relevant          com.anydo  \n",
      "4       4.14.0.4  most_relevant          com.anydo  \n",
      "...          ...            ...                ...  \n",
      "16782      6.1.4         newest  com.appxy.planner  \n",
      "16783      6.1.4         newest  com.appxy.planner  \n",
      "16784      6.1.3         newest  com.appxy.planner  \n",
      "16785      6.1.3         newest  com.appxy.planner  \n",
      "16786      6.1.3         newest  com.appxy.planner  \n",
      "\n",
      "[16787 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "df['content'] = df['content'].apply(lemmatize_words)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9625c8-4bc7-4bbe-aca5-fa22f0e8c8f9",
   "metadata": {},
   "source": [
    "## STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b0ba6ad-6a2d-4b1c-9bde-ce6845a8ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "def apply_stemming(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [porter.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "\n",
    "df['content'] = df['content'].apply(apply_stemming)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f17ccf-470f-4399-9725-f742c9418e08",
   "metadata": {},
   "source": [
    "## Export pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ed743-f46f-4ae9-9855-ee989cdf9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DataPreProcessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
