{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177ee51a-6169-411a-8842-730a6d132bbc",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7de0d2-755b-4728-9f7f-be3807573bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2005eb83-5255-4df6-a405-d10fbf18e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Emotions_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fedf04b-61f6-474d-926b-c2a82c46ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1fc4c0-4c7b-4062-86ef-bfeaa83cd88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\masne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\masne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cec556b-52e0-4b68-b752-0b2c53c6a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Initialize stemmer and lemmatizer\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Stemming and lemmatization\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "    \n",
    "    # Join the preprocessed words back into a single string\n",
    "    preprocessed_text = ' '.join(lemmatized_words)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67eda012-93d7-4945-a55e-18676dbf6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the 'text' column \n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f52d82-b82d-4023-9057-5f23a9336bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                                  didnt feel humili   \n",
      "1  go feel hopeless damn hope around someon care ...   \n",
      "2               im grab minut post feel greedi wrong   \n",
      "3     ever feel nostalg fireplac know still properti   \n",
      "4                                       feel grouchi   \n",
      "\n",
      "                                                text  \n",
      "0                                  didnt feel humili  \n",
      "1  go feel hopeless damn hope around someon care ...  \n",
      "2               im grab minut post feel greedi wrong  \n",
      "3     ever feel nostalg fireplac know still properti  \n",
      "4                                       feel grouchi  \n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned content\n",
    "print(df[['text', 'text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b5859-2b8f-4346-9876-af7bf962faa7",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45320eba-6eb5-47a8-8116-6c74cdd26a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d344e13-cb12-4fe5-9ca0-97dece18938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame (optional)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the TF-IDF matrix with the original DataFrame\n",
    "df_with_tfidf = pd.concat([df[['text']], tfidf_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32899126-6c68-4d24-89a6-9b9aefdb6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   aa  aaaaaaand  aaaaand  \\\n",
      "0                                  didnt feel humili  0.0        0.0      0.0   \n",
      "1  go feel hopeless damn hope around someon care ...  0.0        0.0      0.0   \n",
      "2               im grab minut post feel greedi wrong  0.0        0.0      0.0   \n",
      "3     ever feel nostalg fireplac know still properti  0.0        0.0      0.0   \n",
      "4                                       feel grouchi  0.0        0.0      0.0   \n",
      "\n",
      "   aaaand  aac  aahhh  aaron   ab  abandon  ...  zombi  zone  zonisamid  zoo  \\\n",
      "0     0.0  0.0    0.0    0.0  0.0      0.0  ...    0.0   0.0        0.0  0.0   \n",
      "1     0.0  0.0    0.0    0.0  0.0      0.0  ...    0.0   0.0        0.0  0.0   \n",
      "2     0.0  0.0    0.0    0.0  0.0      0.0  ...    0.0   0.0        0.0  0.0   \n",
      "3     0.0  0.0    0.0    0.0  0.0      0.0  ...    0.0   0.0        0.0  0.0   \n",
      "4     0.0  0.0    0.0    0.0  0.0      0.0  ...    0.0   0.0        0.0  0.0   \n",
      "\n",
      "   zoom   zq  zucchini  zum  zumba   zz  \n",
      "0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
      "1   0.0  0.0       0.0  0.0    0.0  0.0  \n",
      "2   0.0  0.0       0.0  0.0    0.0  0.0  \n",
      "3   0.0  0.0       0.0  0.0    0.0  0.0  \n",
      "4   0.0  0.0       0.0  0.0    0.0  0.0  \n",
      "\n",
      "[5 rows x 10325 columns]\n"
     ]
    }
   ],
   "source": [
    "# use df_with_tfidf for modeling\n",
    "print(df_with_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a137d-1668-4c96-9abd-7153e46b55ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
