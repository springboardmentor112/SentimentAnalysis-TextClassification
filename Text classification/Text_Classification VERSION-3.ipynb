{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24c6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e22f430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                i didnt feel humiliated      0\n",
       "1      i can go from feeling so hopeless to so damned...      0\n",
       "2       im grabbing a minute to post i feel greedy wrong      3\n",
       "3      i am ever feeling nostalgic about the fireplac...      2\n",
       "4                                   i am feeling grouchy      3\n",
       "...                                                  ...    ...\n",
       "15995  i just had a very brief time in the beanbag an...      0\n",
       "15996  i am now turning and i feel pathetic that i am...      0\n",
       "15997                     i feel strong and good overall      1\n",
       "15998  i feel like this was such a rude comment and i...      3\n",
       "15999  i know a lot but i feel so stupid because i ca...      0\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Emotions_training.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160c7db",
   "metadata": {},
   "source": [
    "# lower case convertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec5557",
   "metadata": {},
   "source": [
    "use the string in built fucntion \"str.lower()\" for the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84eca250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lowercase\n",
    "df['text']=df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9f0e8",
   "metadata": {},
   "source": [
    "# REMOVING THE LINK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22c86e",
   "metadata": {},
   "source": [
    "removal of the link using the regular expression of the pattern or starts with http\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c25bc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove links\n",
    "import re\n",
    "\n",
    "text = df['text']\n",
    "\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# Apply the function to remove links from each text in the 'text' column\n",
    "df['text'] = df['text'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe66df8",
   "metadata": {},
   "source": [
    "# Remove next lines (\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e70eb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\\n\" refers to the next line and by replacing the \"\\n\" with empty string \n",
    "df['text'] = df['text'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee399a5",
   "metadata": {},
   "source": [
    "# Removal of Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0716a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words containing numbers\n",
    "text=df['text']\n",
    "def remove_words_with_numbers(text):\n",
    "    words = text.split() \n",
    "    clean_words = [] \n",
    "    for word in words:\n",
    "        has_digit = False\n",
    "        for char in word:\n",
    "            if char.isdigit():\n",
    "                has_digit = True\n",
    "                break\n",
    "        if not has_digit:\n",
    "            clean_words.append(word)  # If the word does not contain any digit, add it to the clean words list\n",
    "    return' '.join(clean_words)  # Join the clean words list back to string\n",
    "df['text'] = df['text'].apply(remove_words_with_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920d494",
   "metadata": {},
   "source": [
    "# REMOVE whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c9a0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip() function used to remove trailing whitespaces\n",
    "df['text'] = df['text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e76254",
   "metadata": {},
   "source": [
    "# REMOVE Special characters and EMOJIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ec6eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters \n",
    "def remove_special_characters(text):\n",
    "    special_characters = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    for char in special_characters:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bcacd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove emojis\n",
    "import emoji\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with a 'content' column containing text with emojis\n",
    "text = df['text']\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "# Applying remove_emojis() function to each element of the 'content' column\n",
    "text_without_emojis = text.apply(remove_emojis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec3454",
   "metadata": {},
   "source": [
    "# Removal of stop words using gensim library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906780ed",
   "metadata": {},
   "source": [
    "**Gensim, a popular Python library for topic modeling and natural language processing, offers the remove_stopwords function to eliminate common stopwords from text data. By invoking this function, you can efficiently preprocess text by removing irrelevant words like \"the,\" \"is,\" and \"and,\" facilitating downstream analysis tasks such as text classification or topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "efd374f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "df['text'] = [' '.join(preprocess_string(text)) for text in df['text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549caa9",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b9d06",
   "metadata": {},
   "source": [
    "**Stemming is a natural language processing technique used to reduce words to their root or base form, enabling normalization and simplification of text data. It helps in improving text analysis tasks such as information retrieval, sentiment analysis, and topic modeling by treating variations of words as a single entity. Popular stemming algorithms include Porter Stemmer, Snowball Stemmer, and Lancaster Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10d430c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "#Tokenization is the process of breaking down a text or document into smaller units\n",
    "\n",
    "ps = PorterStemmer() #PorterStemmer is used for stemming, which is the process of reducing words to their base or root form\n",
    "\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    words = word_tokenize(sentence) \n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(stem_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319bb8b",
   "metadata": {},
   "source": [
    "# difference between stemming and lemitizing\n",
    "**Stemming involves stripping affixes from words to get to the root form. It's done using simple and fast heuristic algorithms, which may result in the stem not being a valid word. For example, \"running\" would be stemmed to \"run\".\n",
    "\n",
    "**Lemmatization, on the other hand, considers the context and meaning of the word along with its morphology to reduce it to its base or dictionary form (lemma). It often requires more computational resources and linguistic knowledge but results in valid words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db39b9a",
   "metadata": {},
   "source": [
    "# LEMITIZING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85801c65",
   "metadata": {},
   "source": [
    "Lemmatization is a linguistic process used to reduce words to their base or canonical form, known as the lemma, by considering the word's meaning and context. Unlike stemming, which simply removes suffixes or prefixes, lemmatization ensures that the resulting word is a valid one found in the language's dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b113c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yashas.m/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yashas.m/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemitizing \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4de05481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens] #lemmatize each token in the list of tokens\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308adea",
   "metadata": {},
   "source": [
    "**this below code helps in adding the different label classes into the respective arrays created for each labels \n",
    "and the displaying the count of each classes/label-0,1,2,3,4,5 that is sadness,joy,love,anger,fear and surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11c0eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of sadness is: 4666\n",
      "the count of joy is: 5362\n",
      "the count of love is: 1304\n",
      "the count of anger is: 2159\n",
      "the count of fear is: 1937\n",
      "the count of surprise is : 572\n"
     ]
    }
   ],
   "source": [
    "count = df['text'].count()# total count of the data/sample in the dataset\n",
    "label=df['label'] \n",
    "text=df['text']\n",
    "#creating the empty arrays \n",
    "label0 = []\n",
    "label1 = []\n",
    "label2 = []\n",
    "label3 = []\n",
    "label4 = []\n",
    "label5 = []\n",
    "#this for loop helps in appending the each sample/data into the respective labels array based on the if conditions\n",
    "for i in range(count):\n",
    "    if label[i] == 0:\n",
    "        label0.append(text[i])\n",
    "    elif label[i] == 1:\n",
    "        label1.append(text[i])\n",
    "    elif label[i] == 2:\n",
    "        label2.append(text[i])\n",
    "    elif label[i] == 3:\n",
    "        label3.append(text[i])\n",
    "    elif label[i] == 4:\n",
    "        label4.append(text[i])\n",
    "        \n",
    "    elif label[i]==5:\n",
    "        label5.append(text[i])\n",
    "    else:\n",
    "        pass\n",
    "#displaying the length of each labels \n",
    "print(\"the count of sadness is:\",len(label0))\n",
    "print(\"the count of joy is:\",len(label1))\n",
    "print(\"the count of love is:\",len(label2))\n",
    "print(\"the count of anger is:\",len(label3))\n",
    "print(\"the count of fear is:\",len(label4))\n",
    "print(\"the count of surprise is :\",len(label5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29541e4f",
   "metadata": {},
   "source": [
    "**percentage of each  label in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e98144f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the perecentage of leabel\n",
      " 0=29.1625% \n",
      " 1=33.5125% \n",
      " 2=8.15% \n",
      " 3=13.493749999999999% \n",
      " 4=12.106250000000001% \n",
      " 5=3.5749999999999997%\n"
     ]
    }
   ],
   "source": [
    "#individual percentage\n",
    "l0=(len(label0)/count)*100\n",
    "l1=(len(label1)/count)*100\n",
    "l2=(len(label2)/count)*100\n",
    "l3=(len(label3)/count)*100\n",
    "l4=(len(label4)/count)*100\n",
    "l5=(len(label5)/count)*100\n",
    "print(f\"the perecentage of leabel\\n 0={l0}% \\n 1={l1}% \\n 2={l2}% \\n 3={l3}% \\n 4={l4}% \\n 5={l5}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887f65b",
   "metadata": {},
   "source": [
    "# BAR graph representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0d1ce",
   "metadata": {},
   "source": [
    "**this helps to visualize the each label and helps in finding out whether the dataset is imbalanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70d22bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "labels = ['sadness', 'joy', 'love', 'anger','fear','surprise']\n",
    "counts = [len(label0), len(label1), len(label2), len(label3), len(label4),len(label5)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=labels, y=counts)\n",
    "plt.title('Count of each labels')\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8144fb",
   "metadata": {},
   "source": [
    "**In the above bar graph it denotes that the text related to the joy-1 is maximum and text related to the surprise  label -5 is minimum "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa950a80",
   "metadata": {},
   "source": [
    "# Balancing the dataset classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a73d4",
   "metadata": {},
   "source": [
    "**oversampling is better than under_sampling bcoz there might be some important data misses in the undersample due to less data or reduction od data size in each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e2c29",
   "metadata": {},
   "source": [
    "resample module from scikit-learn's utils subpackage provides functions for resampling data, particularly useful for addressing class imbalance in classification tasks. It allows you to randomly oversample minority classes or undersample majority classes to balance the dataset, improving the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807bb998",
   "metadata": {},
   "source": [
    "label-1 had the maximum samples / text so we have upsampled / increased the all minority classes until it reaches the label-1 sample count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05a99db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5362\n",
      "0    5362\n",
      "3    5362\n",
      "4    5362\n",
      "2    5362\n",
      "5    5362\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Count the number of samples in each class\n",
    "class_counts = df['label'].value_counts()\n",
    "\n",
    "# target count using maximum count among all the label \n",
    "target_count = class_counts.max()\n",
    "\n",
    "\n",
    "resampled_data = []\n",
    "\n",
    "# Loop through each class\n",
    "for label in class_counts.index:\n",
    "    # Extract data for the current class\n",
    "    class_data = df[df['label'] == label]\n",
    "    \n",
    "    # Upsample (oversample) the class to match the target count\n",
    "    sampled_data = resample(class_data, replace=True, n_samples=target_count, random_state=42)\n",
    "    \n",
    "    # Append the resampled data to the list\n",
    "    resampled_data.append(sampled_data)\n",
    "\n",
    "# Concatenate the resampled data for all classes\n",
    "balanced_df = pd.concat(resampled_data)\n",
    "\n",
    "# Displaying the count of samples in each class after balancing the dataset classes \n",
    "print(balanced_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e18215b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>feel glad justic serv west said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15585</th>\n",
       "      <td>feel valuabl know consid worth sacrif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>certainli felt appropri life supplic life life...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11161</th>\n",
       "      <td>feel assur futur onlin entertain rest good hand</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9145</th>\n",
       "      <td>feel thank abl figur wai deal minor effect dealt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>feel game strang realiti swarm violent carnivo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>talk district leader elder hill night explain ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>know isnt real feel strang time</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>feel kinda strang cau didnt encount feel year</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>mean recollect feel funni funni sort wai stori...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32172 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2491                     feel glad justic serv west said      1\n",
       "15585              feel valuabl know consid worth sacrif      1\n",
       "15488  certainli felt appropri life supplic life life...      1\n",
       "11161    feel assur futur onlin entertain rest good hand      1\n",
       "9145    feel thank abl figur wai deal minor effect dealt      1\n",
       "...                                                  ...    ...\n",
       "15825  feel game strang realiti swarm violent carnivo...      5\n",
       "5319   talk district leader elder hill night explain ...      5\n",
       "4775                     know isnt real feel strang time      5\n",
       "1756       feel kinda strang cau didnt encount feel year      5\n",
       "3361   mean recollect feel funni funni sort wai stori...      5\n",
       "\n",
       "[32172 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "113154c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGDCAYAAAAs+rl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaRUlEQVR4nO3df9jddX3f8efLBAFBECTQNAFDJ3UCG1gixWL9UZ3EHy10l9BYFeyY2Sg6f00H1Vm1zeY2x7i0gmPWEaqCsepAERUR4bJDMEEEASmpCMQgiVAnWEsbfO+P84k9DXdyn4T73D8+PB/Xda7zPe/v53PO+3wv8XV/f+R7UlVIkqR+PW6mG5AkSeNl2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVNKslvJ7k7yYNJnjFNn3l+kj8eceySJJVk/ghjn5dk/U72tNNzpZlk2EvTKMnvJlnTQvOeJJclefY0fG4leeqjeIv3Aa+rqj2r6ptT1Zek6WHYS9MkyZuBs4H/BBwAHAScAxw/g22N6inAzTPdhKSdY9hL0yDJ3sB7gNOr6tNV9ZOq+vuq+mxVvbWN2TXJ2Uk2tMfZSXZt616T5GtbvefP99bbIe8PJrk0yQNJrk3yT9q6q9uUb7UjCr8zQX+PS/KOJHcm2ZjkgiR7t54eBOa1+X+1je/3T5NcnuT+JLclOWlo3UuTfDPJj9upgHdtNffZSf5vkh+19a8ZWr3PRN9phO39e0lubfO+m+TfTDDmD5L8MMn3krxyqL5rkvcluSvJvUk+lGT3UT5Xmq0Me2l6PAvYDfjMdsa8HTgGOBI4AjgaeMcOfMYrgHcD+wDrgJUAVfWctv6Idhj+ExPMfU17PB/4JWBP4E+q6qGq2nNo/iPCNskewOXAx4H9Wx/nJDmsDfkJcDLwJOClwGlJTmhzDwIuAz4ALGjf/YbJvtMINgIvA/YCfg/4H0l+ZWj9LwD7AYuAU4DzkjytrfsvwC+3Xp7axrxzxM+VZiXDXpoeTwZ+WFWbtzPmlcB7qmpjVW1iEHKv3oHP+HRVXdc+42MMwmpUrwTOqqrvVtWDwJnA8lEueGMQqt+rqv9dVZur6nrgU8DLAarqq1V1U1X9rKpuBC4Enjv0uV+uqgvbkY77quqGR/udqurSqvqrGrgK+BLw61sN+4/tj5mrgEuBk5IEeC3wpqq6v6oeYHDaZfkonyvNVqP8hyzp0bsP2C/J/O0E/i8Cdw69vrPVRvWDoeW/YbB3PqqJPns+g2sLvj/J3KcAv5rkR0O1+cCfAST5VeC9wOHA44FdgU+2cQcCE54aaHbqOyV5MfCHDPbQHwc8AbhpaMhfV9VPhl5v2dYL2ti1g9wfvB2D0xjSnOWevTQ9rgH+FjhhO2M2MAjOLQ5qNRgcCn/ClhVJfmGK+5voszcD944w927gqqp60tBjz6o6ra3/OHAJcGBV7Q18iEGAbpk70nn4UbXrHD7F4F8QHFBVTwI+P/SZMLgWYI+h11u29Q+BnwKHDX2XvYdOZUhzkmEvTYOq+n8Mzvt+MMkJSZ6QZJckL07yX9uwC4F3JFmQZL82/qNt3beAw5IcmWQ34F072MK9DM7Fb8uFwJuSHJxkTwaHrj8xyWmHLT4H/HKSV7fvtEuSZyZ5elv/ROD+qvrbJEcDvzs092PAC5OclGR+kicnOXIHv9vWthw92ARsbnv5L5pg3LuTPD7JrzM4FfHJqvoZ8L8YnOPfHyDJoiTHPcqepBll2EvTpKrOAt7M4KK7TQz2al8H/J825I+BNcCNDA45X99qVNVfMria/8vA7cA/ujJ/BO8CVrUr3k+aYP1HGBx2vxq4g8FRiNeP+L0eYBCmyxnsHf+AwUVuu7Yhvw+8J8kDDP6AWT009y7gJcBbgPsZXJx3xI59tQn7+Xftc/6awR8Xl2w17Adt3QYGf3D826r6Tlv3HxhcDPj1JD9msM2fhjSHpapmugdJkjRG7tlLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmd6/YOevvtt18tWbJkptuQJGlarF279odVtWCidd2G/ZIlS1izZs1MtyFJ0rRIcue21nkYX5Kkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSepct796tz1HvfWCmW5hWq39byfv9Ny73vPPprCT2e2gd96003OP/cCxU9jJ7PYXr/+LnZ571XOeO4WdzH7PvfqqnZ77J2/57BR2Mru97r//5k7PXfmql09hJ7Pf2z/65zs1zz17SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjo31rBP8r0kNyW5IcmaVts3yeVJbm/P+wyNPzPJuiS3JTluqH5Ue591Sd6fJOPsW5KknkzHnv3zq+rIqlraXp8BXFFVhwBXtNckORRYDhwGLAPOSTKvzTkXWAEc0h7LpqFvSZK6MBOH8Y8HVrXlVcAJQ/WLquqhqroDWAccnWQhsFdVXVNVBVwwNEeSJE1i3GFfwJeSrE2yotUOqKp7ANrz/q2+CLh7aO76VlvUlreuP0KSFUnWJFmzadOmKfwakiTNXfPH/P7HVtWGJPsDlyf5znbGTnQevrZTf2Sx6jzgPIClS5dOOEaSpMease7ZV9WG9rwR+AxwNHBvOzRPe97Yhq8HDhyavhjY0OqLJ6hLkqQRjC3sk+yR5IlbloEXAd8GLgFOacNOAS5uy5cAy5PsmuRgBhfiXdcO9T+Q5Jh2Ff7JQ3MkSdIkxnkY/wDgM+1fyc0HPl5VX0jyDWB1klOBu4ATAarq5iSrgVuAzcDpVfVwe6/TgPOB3YHL2kOSJI1gbGFfVd8Fjpigfh/wgm3MWQmsnKC+Bjh8qnuUJOmxwDvoSZLUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUubGHfZJ5Sb6Z5HPt9b5JLk9ye3veZ2jsmUnWJbktyXFD9aOS3NTWvT9Jxt23JEm9mI49+zcAtw69PgO4oqoOAa5or0lyKLAcOAxYBpyTZF6bcy6wAjikPZZNQ9+SJHVhrGGfZDHwUuDDQ+XjgVVteRVwwlD9oqp6qKruANYBRydZCOxVVddUVQEXDM2RJEmTGPee/dnA24CfDdUOqKp7ANrz/q2+CLh7aNz6VlvUlreuP0KSFUnWJFmzadOmKfkCkiTNdWML+yQvAzZW1dpRp0xQq+3UH1msOq+qllbV0gULFoz4sZIk9W3+GN/7WOC3krwE2A3YK8lHgXuTLKyqe9oh+o1t/HrgwKH5i4ENrb54grokSRrB2Pbsq+rMqlpcVUsYXHj3lap6FXAJcEobdgpwcVu+BFieZNckBzO4EO+6dqj/gSTHtKvwTx6aI0mSJjHOPftteS+wOsmpwF3AiQBVdXOS1cAtwGbg9Kp6uM05DTgf2B24rD0kSdIIpiXsq+qrwFfb8n3AC7YxbiWwcoL6GuDw8XUoSVK/vIOeJEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdG1vYJ9ktyXVJvpXk5iTvbvV9k1ye5Pb2vM/QnDOTrEtyW5LjhupHJbmprXt/koyrb0mSejNS2Cc5dpTaVh4CfqOqjgCOBJYlOQY4A7iiqg4BrmivSXIosBw4DFgGnJNkXnuvc4EVwCHtsWyUviVJ0uh79h8YsfZzNfBge7lLexRwPLCq1VcBJ7Tl44GLquqhqroDWAccnWQhsFdVXVNVBVwwNEeSJE1i/vZWJnkW8GvAgiRvHlq1FzBv4ln/aP48YC3wVOCDVXVtkgOq6h6Aqronyf5t+CLg60PT17fa37flresTfd4KBkcAOOiggyZrT5Kkx4TJ9uwfD+zJ4I+CJw49fgy8fLI3r6qHq+pIYDGDvfTDtzN8ovPwtZ36RJ93XlUtraqlCxYsmKw9SZIeE7a7Z19VVwFXJTm/qu7c2Q+pqh8l+SqDc+33JlnY9uoXAhvbsPXAgUPTFgMbWn3xBHVJkjSCUc/Z75rkvCRfSvKVLY/tTUiyIMmT2vLuwAuB7wCXAKe0YacAF7flS4DlSXZNcjCDC/Gua4f8H0hyTLsK/+ShOZIkaRLb3bMf8kngQ8CHgYdHnLMQWNXO2z8OWF1Vn0tyDbA6yanAXcCJAFV1c5LVwC3AZuD0qtryWacB5wO7A5e1hyRJGsGoYb+5qs7dkTeuqhuBZ0xQvw94wTbmrARWTlBfA2zvfL8kSdqGUQ/jfzbJ7ydZ2G6Ks2+SfcfamSRJmhKj7tlvOcf+1qFaAb80te1IkqSpNlLYV9XB425EkiSNx0hhn+TkiepVdcHUtiNJkqbaqIfxnzm0vBuDC+yuZ3DrWkmSNIuNehj/9cOvk+wN/NlYOpIkSVNqZ3/i9m8Y3PRGkiTNcqOes/8s/3A/+nnA04HV42pKkiRNnVHP2b9vaHkzcGdVrd/WYEmSNHuMdBi//SDOdxj84t0+wN+NsylJkjR1Rgr7JCcB1zG4j/1JwLVJJv2JW0mSNPNGPYz/duCZVbURBr9oB3wZ+PNxNSZJkqbGqFfjP25L0Df37cBcSZI0g0bds/9Cki8CF7bXvwN8fjwtSZKkqbTdsE/yVOCAqnprkn8JPBsIcA3wsWnoT5IkPUqTHYo/G3gAoKo+XVVvrqo3MdirP3u8rUmSpKkwWdgvqaobty5W1RpgyVg6kiRJU2qysN9tO+t2n8pGJEnSeEwW9t9I8tqti0lOBdaOpyVJkjSVJrsa/43AZ5K8kn8I96XA44HfHmNfkiRpimw37KvqXuDXkjwfOLyVL62qr4y9M0mSNCVG/T37K4Erx9yLJEkaA++CJ0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6N7awT3JgkiuT3Jrk5iRvaPV9k1ye5Pb2vM/QnDOTrEtyW5LjhupHJbmprXt/koyrb0mSejPOPfvNwFuq6unAMcDpSQ4FzgCuqKpDgCvaa9q65cBhwDLgnCTz2nudC6wADmmPZWPsW5Kkrowt7Kvqnqq6vi0/ANwKLAKOB1a1YauAE9ry8cBFVfVQVd0BrAOOTrIQ2KuqrqmqAi4YmiNJkiYxLefskywBngFcCxxQVffA4A8CYP82bBFw99C09a22qC1vXZckSSMYe9gn2RP4FPDGqvrx9oZOUKvt1Cf6rBVJ1iRZs2nTph1vVpKkDo017JPswiDoP1ZVn27le9uhedrzxlZfDxw4NH0xsKHVF09Qf4SqOq+qllbV0gULFkzdF5EkaQ4b59X4Af4UuLWqzhpadQlwSls+Bbh4qL48ya5JDmZwId517VD/A0mOae958tAcSZI0ifljfO9jgVcDNyW5odX+AHgvsDrJqcBdwIkAVXVzktXALQyu5D+9qh5u804Dzgd2By5rD0mSNIKxhX1VfY2Jz7cDvGAbc1YCKyeorwEOn7ruJEl67PAOepIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdW5sYZ/kI0k2Jvn2UG3fJJcnub097zO07swk65LcluS4ofpRSW5q696fJOPqWZKkHo1zz/58YNlWtTOAK6rqEOCK9pokhwLLgcPanHOSzGtzzgVWAIe0x9bvKUmStmNsYV9VVwP3b1U+HljVllcBJwzVL6qqh6rqDmAdcHSShcBeVXVNVRVwwdAcSZI0guk+Z39AVd0D0J73b/VFwN1D49a32qK2vHVdkiSNaLZcoDfRefjaTn3iN0lWJFmTZM2mTZumrDlJkuay6Q77e9uhedrzxlZfDxw4NG4xsKHVF09Qn1BVnVdVS6tq6YIFC6a0cUmS5qrpDvtLgFPa8inAxUP15Ul2TXIwgwvxrmuH+h9Icky7Cv/koTmSJGkE88f1xkkuBJ4H7JdkPfCHwHuB1UlOBe4CTgSoqpuTrAZuATYDp1fVw+2tTmNwZf/uwGXtIUmSRjS2sK+qV2xj1Qu2MX4lsHKC+hrg8ClsTZKkx5TZcoGeJEkaE8NekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnTPsJUnqnGEvSVLnDHtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr0kSZ0z7CVJ6pxhL0lS5wx7SZI6Z9hLktQ5w16SpM4Z9pIkdc6wlySpc4a9JEmdM+wlSeqcYS9JUucMe0mSOmfYS5LUuTkT9kmWJbktybokZ8x0P5IkzRVzIuyTzAM+CLwYOBR4RZJDZ7YrSZLmhjkR9sDRwLqq+m5V/R1wEXD8DPckSdKcMFfCfhFw99Dr9a0mSZImkaqa6R4mleRE4Liq+tft9auBo6vq9VuNWwGsaC+fBtw2rY1Obj/ghzPdxBzgdhqd22o0bqfRua1GMxu301OqasFEK+ZPdyc7aT1w4NDrxcCGrQdV1XnAedPV1I5Ksqaqls50H7Od22l0bqvRuJ1G57YazVzbTnPlMP43gEOSHJzk8cBy4JIZ7kmSpDlhTuzZV9XmJK8DvgjMAz5SVTfPcFuSJM0JcyLsAarq88DnZ7qPR2nWnmKYZdxOo3NbjcbtNDq31Wjm1HaaExfoSZKknTdXztlLkqSdZNhPA2/1O5okH0myMcm3Z7qX2SzJgUmuTHJrkpuTvGGme5qtkuyW5Lok32rb6t0z3dNslmRekm8m+dxM9zKbJflekpuS3JBkzUz3MwoP449Zu9XvXwL/gsE/IfwG8IqqumVGG5uFkjwHeBC4oKoOn+l+ZqskC4GFVXV9kicCa4ET/N/UIyUJsEdVPZhkF+BrwBuq6usz3NqslOTNwFJgr6p62Uz3M1sl+R6wtKpm27+z3yb37MfPW/2OqKquBu6f6T5mu6q6p6qub8sPALfiHSUnVAMPtpe7tId7OBNIshh4KfDhme5FU8+wHz9v9auxSbIEeAZw7Qy3Mmu1Q9M3ABuBy6vKbTWxs4G3AT+b4T7mggK+lGRtu3PrrGfYj18mqLlnoUctyZ7Ap4A3VtWPZ7qf2aqqHq6qIxncefPoJJ4i2kqSlwEbq2rtTPcyRxxbVb/C4JdYT2+nIGc1w378RrrVr7Qj2vnnTwEfq6pPz3Q/c0FV/Qj4KrBsZjuZlY4Ffqudi74I+I0kH53ZlmavqtrQnjcCn2FwunZWM+zHz1v9akq1i87+FLi1qs6a6X5msyQLkjypLe8OvBD4zow2NQtV1ZlVtbiqljD4/6ivVNWrZritWSnJHu3CWJLsAbwImPX/gsiwH7Oq2gxsudXvrcBqb/U7sSQXAtcAT0uyPsmpM93TLHUs8GoGe183tMdLZrqpWWohcGWSGxn84X15VfnPyvRoHAB8Lcm3gOuAS6vqCzPc06T8p3eSJHXOPXtJkjpn2EuS1DnDXpKkzhn2kiR1zrCXJKlzhr2kbUry4OSjfj72XUn+/bjeX9LOM+wlSeqcYS9phyT5zSTXtt89/3KSA4ZWH5HkK0luT/LaoTlvTfKNJDf6m/LS9DPsJe2orwHHVNUzGNxH/W1D6/45g59JfRbwziS/mORFwCEM7h9+JHDUXPjhEKkn82e6AUlzzmLgE0kWAo8H7hhad3FV/RT4aZIrGQT8sxncP/ybbcyeDML/6ulrWXpsM+wl7agPAGdV1SVJnge8a2jd1vffLgY/8/yfq+p/Tkt3kh7Bw/iSdtTewPfb8ilbrTs+yW5Jngw8j8GPz3wR+FdJ9gRIsijJ/tPVrCT37CVt3xOSrB96fRaDPflPJvk+8HXg4KH11wGXAgcBf9R+93tDkqcD1wx+nZcHgVcBG8ffviTwV+8kSeqeh/ElSeqcYS9JUucMe0mSOmfYS5LUOcNekqTOGfaSJHXOsJckqXOGvSRJnfv/dfGClmMq1EQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the count of each label\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=balanced_df)\n",
    "plt.title('Count of each label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2c580",
   "metadata": {},
   "source": [
    "**vectorization-\n",
    "Text vectorization converts text data into numerical vectors, representing features such as word frequencies or semantic meanings. This transformation allows machine learning algorithms to process and analyze text, enabling tasks like sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95b24828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Handle NaN values by replacing them with an empty string\n",
    "balanced_df['text'].fillna('', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13a01f",
   "metadata": {},
   "source": [
    "## SPLITTING OF DATASET INTO TRAIN[70%],TEST[20%] AND VALIDATE [10%] DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2954911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=balanced_df['label']\n",
    "X=balanced_df['text']\n",
    "# First, split the dataset into Train (70%) and combined Test-Validation (30%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Then, split the combined Train-Validation set into Train (70%) and Validation (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327430fb",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2d094",
   "metadata": {},
   "source": [
    "**Random Forest is a popular ensemble learning algorithm that builds multiple decision trees during training and combines their predictions through voting or averaging. It's robust against overfitting, capable of handling large datasets with high dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25aad37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4520)\t0.5651842666298269\n",
      "  (0, 4446)\t0.634679316545963\n",
      "  (0, 1632)\t0.1007700063907416\n",
      "  (0, 2014)\t0.5172951920469243\n",
      "  (1, 3680)\t0.3504903266339963\n",
      "  (1, 2890)\t0.3641792934981834\n",
      "  (1, 4563)\t0.5885715920142044\n",
      "  (1, 4035)\t0.3937925349703988\n",
      "  (1, 3731)\t0.3711215575501946\n",
      "  (1, 4444)\t0.3183783990919032\n",
      "  (1, 1632)\t0.06280826467755082\n",
      "  (2, 4575)\t0.3737478075940897\n",
      "  (2, 4390)\t0.2816357551707891\n",
      "  (2, 268)\t0.4014822198713139\n",
      "  (2, 4325)\t0.32178403096240776\n",
      "  (2, 4207)\t0.4554492926449436\n",
      "  (2, 3686)\t0.30275607000087223\n",
      "  (2, 4811)\t0.3782587907897127\n",
      "  (2, 1903)\t0.26673918041748296\n",
      "  (2, 1632)\t0.05418618827836145\n",
      "  (3, 379)\t0.37364708274769937\n",
      "  (3, 2319)\t0.2633119671274495\n",
      "  (3, 3045)\t0.3769066606428497\n",
      "  (3, 3115)\t0.3081514111183108\n",
      "  (3, 4909)\t0.3977811110265329\n",
      "  :\t:\n",
      "  (15008, 2183)\t0.8079514510757316\n",
      "  (15008, 1632)\t0.2410084452175685\n",
      "  (15009, 782)\t0.442612221951488\n",
      "  (15009, 20)\t0.46697934361199545\n",
      "  (15009, 3405)\t0.36463402213868445\n",
      "  (15009, 2034)\t0.29099261956255457\n",
      "  (15009, 4920)\t0.33990811330666315\n",
      "  (15009, 2123)\t0.303085963991563\n",
      "  (15009, 4336)\t0.397766828248702\n",
      "  (15009, 1632)\t0.05265892291474942\n",
      "  (15010, 3891)\t0.6348412312014219\n",
      "  (15010, 13)\t0.43307638253423003\n",
      "  (15010, 830)\t0.4755734227894979\n",
      "  (15010, 1593)\t0.42052116551794566\n",
      "  (15010, 1632)\t0.08008325009287684\n",
      "  (15011, 4958)\t0.5679671793153146\n",
      "  (15011, 1255)\t0.6924902051068426\n",
      "  (15011, 2534)\t0.4308962197088235\n",
      "  (15011, 1632)\t0.11044929557192205\n",
      "  (15012, 4508)\t0.5521274011641735\n",
      "  (15012, 3052)\t0.395977112798896\n",
      "  (15012, 3455)\t0.4828664298975667\n",
      "  (15012, 1897)\t0.40626035390015247\n",
      "  (15012, 400)\t0.36441083664919294\n",
      "  (15012, 1632)\t0.08575976260859534\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "print(X_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9de62fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64cec519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare the data\n",
    "texts = balanced_df['text'].values\n",
    "labels = balanced_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f603c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (32172, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f445daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 22520, Testing samples: 6434, Validation samples: 3218\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (70%), testing (20%), and validation (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.3333, random_state=42)  # 0.3333 * 0.3 â‰ˆ 0.10\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}, Validation samples: {X_val.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db024eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1097\n",
      "           1       0.92      0.87      0.90      1104\n",
      "           2       0.92      0.94      0.93      1069\n",
      "           3       0.92      0.96      0.94      1053\n",
      "           4       0.95      0.93      0.94      1054\n",
      "           5       0.95      1.00      0.97      1057\n",
      "\n",
      "    accuracy                           0.93      6434\n",
      "   macro avg       0.93      0.93      0.93      6434\n",
      "weighted avg       0.93      0.93      0.93      6434\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 980   27   20   38   25    7]\n",
      " [  38  963   59   18   15   11]\n",
      " [  13   39 1002    6    8    1]\n",
      " [  16    7    6 1009    8    7]\n",
      " [   9    6    6   25  977   31]\n",
      " [   0    0    0    0    0 1057]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression classifier\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91db41d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1097\n",
      "           1       0.95      0.93      0.94      1104\n",
      "           2       0.96      0.98      0.97      1069\n",
      "           3       0.96      0.97      0.96      1053\n",
      "           4       0.98      0.97      0.97      1054\n",
      "           5       0.98      1.00      0.99      1057\n",
      "\n",
      "    accuracy                           0.96      6434\n",
      "   macro avg       0.96      0.96      0.96      6434\n",
      "weighted avg       0.96      0.96      0.96      6434\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1029   23    5   25   13    2]\n",
      " [  23 1023   32   11    8    7]\n",
      " [   9   12 1047    0    0    1]\n",
      " [  14   14    2 1018    5    0]\n",
      " [   6    5    3    6 1022   12]\n",
      " [   0    0    0    0    0 1057]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d416e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Random Forest Classification Report (After Hyperparameter Tuning):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1097\n",
      "           1       0.75      0.83      0.79      1104\n",
      "           2       0.84      0.90      0.87      1069\n",
      "           3       0.91      0.90      0.90      1053\n",
      "           4       0.95      0.82      0.88      1054\n",
      "           5       0.89      0.99      0.94      1057\n",
      "\n",
      "    accuracy                           0.87      6434\n",
      "   macro avg       0.88      0.87      0.87      6434\n",
      "weighted avg       0.88      0.87      0.87      6434\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 874  103   53   36   19   12]\n",
      " [  21  921   95   26   17   24]\n",
      " [   4   91  963    4    5    2]\n",
      " [  28   57   16  944    3    5]\n",
      " [  11   45   20   33  865   80]\n",
      " [   0    9    0    0    0 1048]]\n",
      "Best parameters found: {'max_depth': 20, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report (After Hyperparameter Tuning):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  normal dataset ...(without upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2173a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "XGBoost Classification Report (After Hyperparameter Tuning):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       943\n",
      "           1       0.84      0.91      0.88      1068\n",
      "           2       0.84      0.66      0.74       293\n",
      "           3       0.80      0.87      0.83       395\n",
      "           4       0.84      0.83      0.84       379\n",
      "           5       0.69      0.66      0.67       122\n",
      "\n",
      "    accuracy                           0.85      3200\n",
      "   macro avg       0.82      0.80      0.81      3200\n",
      "weighted avg       0.86      0.85      0.85      3200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[827  51   8  35  17   5]\n",
      " [ 23 976  24  21  11  13]\n",
      " [  6  83 193   6   4   1]\n",
      " [ 24  17   2 344   6   2]\n",
      " [  9  18   1  20 315  16]\n",
      " [  2  14   1   3  21  81]]\n",
      "Best parameters found: {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200}\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=100; total time= 1.9min\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=  48.3s\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=100; total time= 1.8min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=  54.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=200; total time= 3.7min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=  55.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=200; total time= 3.7min\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=100; total time= 1.9min\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=100; total time= 1.6min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time= 1.8min\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=200; total time= 3.4min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time= 1.8min\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=  48.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=200; total time= 1.9min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time= 1.8min\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=  49.2s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=200; total time= 1.9min\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=  54.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=20, n_estimators=100; total time= 1.8min\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=100; total time= 1.7min\n",
      "[CV] END ..learning_rate=0.1, max_depth=20, n_estimators=200; total time= 1.8min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "texts = df['text'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Split the data into training (70%), testing (20%), and validation (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.3333, random_state=42)  \n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classification Report (After Hyperparameter Tuning):\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dff5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc7146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
