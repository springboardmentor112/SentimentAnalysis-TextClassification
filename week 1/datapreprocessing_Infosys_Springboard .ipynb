{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e65fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9c396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                    reviewId               userName  \\\n",
       "0      0197c118-5c6f-4a7b-894c-970023d1a350                Mar Zur   \n",
       "1      94868fb5-a21d-4ef9-ab85-81b2ed3d0785           Devin Rivera   \n",
       "2      825da34e-f65d-4ef3-991d-02d5291820d6          Heidi Kinsley   \n",
       "3      a49c2875-651a-4c33-b79c-5813780d659e          Daniel Keller   \n",
       "4      9482c75e-2e63-46ab-8c94-47273dd6a829          A Google user   \n",
       "...                                     ...                    ...   \n",
       "16782  e9cebff8-82ad-4191-b196-127a65e9036d  Alexandra Grafwallner   \n",
       "16783  ab74c21c-3587-4393-a53d-4cb55f3e3c9b          Ljubica Pejic   \n",
       "16784  0062b15d-6e4d-4f0a-9ea6-ef9b9420d923         Kamiyah Dorsey   \n",
       "16785  85318bf2-7ca0-4d5e-8cb2-f0f18c813e4d         Keturah Pender   \n",
       "16786  8e2deadd-1a6a-4817-89dc-4bd9a198332c    Bhagwan Singh Virik   \n",
       "\n",
       "                                               userImage  \\\n",
       "0      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "1      https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "2      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "3      https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "4      https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "...                                                  ...   \n",
       "16782  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "16783  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "16784  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "16785  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "16786  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "\n",
       "                                                 content  thumbsUpCount  \\\n",
       "0      I have the same recurring tasks to do every da...             11   \n",
       "1      Instead of shopping around, I downloaded Any.d...              8   \n",
       "2      Why does every once in a while... out of the b...              6   \n",
       "3      Terrible Update! This app used to be perfect f...              5   \n",
       "4      This app is deceivingly terrible. There are so...             20   \n",
       "...                                                  ...            ...   \n",
       "16782                                      Excellent app              0   \n",
       "16783  I love it. Easy to use. Make my life organize....              9   \n",
       "16784  I love how I could make plans and check the ap...              0   \n",
       "16785                           Exactly what I needed!!!              0   \n",
       "16786                                        Very good ðŸ‘              0   \n",
       "\n",
       "      reviewCreatedVersion                at  \\\n",
       "0                 4.16.6.2  22-07-2020 13:13   \n",
       "1                      NaN  08-12-2020 06:24   \n",
       "2                 5.11.1.2  09-07-2021 13:51   \n",
       "3                      NaN  16-11-2020 01:50   \n",
       "4                 4.14.0.4  31-01-2019 16:19   \n",
       "...                    ...               ...   \n",
       "16782                6.1.4  05-07-2023 02:08   \n",
       "16783                6.1.4  29-06-2023 15:27   \n",
       "16784                6.1.3  28-06-2023 01:04   \n",
       "16785                6.1.3  23-06-2023 13:14   \n",
       "16786                6.1.3  21-06-2023 03:16   \n",
       "\n",
       "                                            replyContent         repliedAt  \\\n",
       "0      Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
       "1      We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
       "2      Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
       "3      Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
       "4      Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
       "...                                                  ...               ...   \n",
       "16782                                                NaN               NaN   \n",
       "16783                                                NaN               NaN   \n",
       "16784                                                NaN               NaN   \n",
       "16785                                                NaN               NaN   \n",
       "16786                                                NaN               NaN   \n",
       "\n",
       "      appVersion      sortOrder              appId  \n",
       "0       4.16.6.2  most_relevant          com.anydo  \n",
       "1            NaN  most_relevant          com.anydo  \n",
       "2       5.11.1.2  most_relevant          com.anydo  \n",
       "3            NaN  most_relevant          com.anydo  \n",
       "4       4.14.0.4  most_relevant          com.anydo  \n",
       "...          ...            ...                ...  \n",
       "16782      6.1.4         newest  com.appxy.planner  \n",
       "16783      6.1.4         newest  com.appxy.planner  \n",
       "16784      6.1.3         newest  com.appxy.planner  \n",
       "16785      6.1.3         newest  com.appxy.planner  \n",
       "16786      6.1.3         newest  com.appxy.planner  \n",
       "\n",
       "[16787 rows x 12 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('reviews.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f2395",
   "metadata": {},
   "source": [
    "# 1.Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7fbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'content' column to lowercase\n",
    "df['content'] = df['content'].str.lower()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df4695",
   "metadata": {},
   "source": [
    "# 2.remove-links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3861f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = df['content']\n",
    "\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# Apply the function to remove links from each text in the 'content' column\n",
    "df['content'] = df['content'].apply(remove_links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d3625",
   "metadata": {},
   "source": [
    "# 3.Remove next lines (\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096e75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\\n\" refers to the next line and by replacing the \"\\n\" with empty string \n",
    "df['content'] = df['content'].str.replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389dd1f3",
   "metadata": {},
   "source": [
    "# 4.Words containing numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee673f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['content']\n",
    "def remove_words_with_numbers(text):\n",
    "    words = text.split() \n",
    "    clean_words = [] \n",
    "    for word in words:\n",
    "        has_digit = False\n",
    "        for char in word:\n",
    "            if char.isdigit():\n",
    "                has_digit = True\n",
    "                break\n",
    "        if not has_digit:\n",
    "            clean_words.append(word)  # If the word does not contain any digit, add it to the clean words list\n",
    "    return ' '.join(clean_words)  # Join the clean words list back to string\n",
    "df['content'] = df['content'].apply(remove_words_with_numbers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239dce3",
   "metadata": {},
   "source": [
    "# 5.extra-space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76c55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip() function used to remove trailing whitespaces\n",
    "df['content'] = df['content'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438950f5",
   "metadata": {},
   "source": [
    "# 6.remove special character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe83291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_special_characters(text):\n",
    "    special_characters = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    for char in special_characters:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(remove_special_characters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3aa950",
   "metadata": {},
   "source": [
    "# 6.remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca84b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.9/site-packages (2.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf85277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with a 'content' column containing text with emojis\n",
    "text = df['content']\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "# Applying remove_emojis() function to each element of the 'content' column\n",
    "text_without_emojis = text.apply(remove_emojis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7722b",
   "metadata": {},
   "source": [
    "# 7.removal of stop word(using genism package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3934e84e",
   "metadata": {},
   "source": [
    "Gensim, a popular Python library for topic modeling and natural language processing, offers the remove_stopwords function to eliminate common stopwords from text data. By invoking this function, you can efficiently preprocess text by removing irrelevant words like \"the,\" \"is,\" and \"and,\" facilitating downstream analysis tasks such as text classification or topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74269263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "df['content'] = [' '.join(preprocess_string(text)) for text in df['content']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9258ad",
   "metadata": {},
   "source": [
    "# 8.Stemming      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebe6ea",
   "metadata": {},
   "source": [
    "Stemming is a natural language processing technique used to reduce words to their root or base form, enabling normalization and simplification of text data. It helps in improving text analysis tasks such as information retrieval, sentiment analysis, and topic modeling by treating variations of words as a single entity. Popular stemming algorithms include Porter Stemmer, Snowball Stemmer, and Lancaster Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90f0134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yashas.m/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK's tokenization functionalities\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0c00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "#Tokenization is the process of breaking down a text or document into smaller units\n",
    "\n",
    "ps = PorterStemmer() #PorterStemmer is used for stemming, which is the process of reducing words to their base or root form\n",
    "\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    words = word_tokenize(sentence) \n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "\n",
    "df['content'] = df['content'].apply(stem_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9cb34",
   "metadata": {},
   "source": [
    "# 9.Lematization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd39f3",
   "metadata": {},
   "source": [
    "Lemmatization is a linguistic process used to reduce words to their base or canonical form, known as the lemma, by considering the word's meaning and context. Unlike stemming, which simply removes suffixes or prefixes, lemmatization ensures that the resulting word is a valid one found in the language's dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63291ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yashas.m/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1753c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yashas.m/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fdb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens] #lemmatize each token in the list of tokens\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "df['content'] = df['content'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e516b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Saving DataFrame to a CSV file\n",
    "df.to_csv('preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a657f005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0197c118-5c6f-4a7b-894c-970023d1a350</td>\n",
       "      <td>Mar Zur</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>recur task dai need todolist remind buzz time ...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.16.6.2</td>\n",
       "      <td>22-07-2020 13:13</td>\n",
       "      <td>Our team will be happy to look into it for you...</td>\n",
       "      <td>23-07-2020 16:32</td>\n",
       "      <td>4.16.6.2</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94868fb5-a21d-4ef9-ab85-81b2ed3d0785</td>\n",
       "      <td>Devin Rivera</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>instead shop download anydo wide set dai sched...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08-12-2020 06:24</td>\n",
       "      <td>We are not aware of any issues with randomized...</td>\n",
       "      <td>10-12-2020 09:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825da34e-f65d-4ef3-991d-02d5291820d6</td>\n",
       "      <td>Heidi Kinsley</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>blue app ask updat acct email task list lost t...</td>\n",
       "      <td>6</td>\n",
       "      <td>5.11.1.2</td>\n",
       "      <td>09-07-2021 13:51</td>\n",
       "      <td>Sorry to hear that! It sounds like you might h...</td>\n",
       "      <td>11-07-2021 11:16</td>\n",
       "      <td>5.11.1.2</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a49c2875-651a-4c33-b79c-5813780d659e</td>\n",
       "      <td>Daniel Keller</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>terribl updat app perfect plan certain task co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-11-2020 01:50</td>\n",
       "      <td>Please note that the tasks in your tasks view ...</td>\n",
       "      <td>17-11-2020 09:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9482c75e-2e63-46ab-8c94-47273dd6a829</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>app deceivingli terribl nice design featur lik...</td>\n",
       "      <td>20</td>\n",
       "      <td>4.14.0.4</td>\n",
       "      <td>31-01-2019 16:19</td>\n",
       "      <td>Hi Ryan, it sounds like you are describing our...</td>\n",
       "      <td>05-02-2019 11:52</td>\n",
       "      <td>4.14.0.4</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId       userName  \\\n",
       "0  0197c118-5c6f-4a7b-894c-970023d1a350        Mar Zur   \n",
       "1  94868fb5-a21d-4ef9-ab85-81b2ed3d0785   Devin Rivera   \n",
       "2  825da34e-f65d-4ef3-991d-02d5291820d6  Heidi Kinsley   \n",
       "3  a49c2875-651a-4c33-b79c-5813780d659e  Daniel Keller   \n",
       "4  9482c75e-2e63-46ab-8c94-47273dd6a829  A Google user   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "2  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "3  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  thumbsUpCount  \\\n",
       "0  recur task dai need todolist remind buzz time ...             11   \n",
       "1  instead shop download anydo wide set dai sched...              8   \n",
       "2  blue app ask updat acct email task list lost t...              6   \n",
       "3  terribl updat app perfect plan certain task co...              5   \n",
       "4  app deceivingli terribl nice design featur lik...             20   \n",
       "\n",
       "  reviewCreatedVersion                at  \\\n",
       "0             4.16.6.2  22-07-2020 13:13   \n",
       "1                  NaN  08-12-2020 06:24   \n",
       "2             5.11.1.2  09-07-2021 13:51   \n",
       "3                  NaN  16-11-2020 01:50   \n",
       "4             4.14.0.4  31-01-2019 16:19   \n",
       "\n",
       "                                        replyContent         repliedAt  \\\n",
       "0  Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
       "1  We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
       "2  Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
       "3  Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
       "4  Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
       "\n",
       "  appVersion      sortOrder      appId  \n",
       "0   4.16.6.2  most_relevant  com.anydo  \n",
       "1        NaN  most_relevant  com.anydo  \n",
       "2   5.11.1.2  most_relevant  com.anydo  \n",
       "3        NaN  most_relevant  com.anydo  \n",
       "4   4.14.0.4  most_relevant  com.anydo  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
