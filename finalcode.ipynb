{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbeda958-4523-4b5f-8eea-ab6d6ed4841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30b08d-bb18-4f5f-a944-5c9121185b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements and understand what each library/module does:\n",
    "#1. import pandas as pd: This line imports the Pandas library and assigns it the alias “pd”. Pandas is a powerful data manipulation library in Python. It provides data structures (such as DataFrames) for efficient handling of structured data.\n",
    "#2. from sklearn.model_selection import train_test_split, GridSearchCV: Here, we’re importing two specific functions from the sklearn.model_selection module:\n",
    "       # a) train_test_split: This function splits a dataset into training and testing subsets. It’s commonly used for evaluating machine learning models.\n",
    "       # b) GridSearchCV: This class performs an exhaustive search over a specified parameter grid to find the best hyperparameters for a given model.\n",
    "#3. from sklearn.feature_extraction.text import TfidfVectorizer: The TfidfVectorizer is used for text feature extraction. It converts a collection of text documents into a matrix of TF-IDF features (Term Frequency-Inverse Document Frequency)\n",
    "#4. from sklearn.metrics import classification_report, confusion_matrix, accuracy_score: These are essential metrics for evaluating classification models:\n",
    "       # a) classification_report: Provides precision, recall, F1-score, and support for each class.\n",
    "       # b) confusion_matrix: Helps visualize true positive, true negative, false positive, and false negative predictions.\n",
    "       # c) accuracy_score: Calculates the accuracy of a classification model.\n",
    "#5. from imblearn.over_sampling import SMOTE: SMOTE (Synthetic Minority Over-sampling Technique) is used for oversampling the minority class in imbalanced datasets. It generates synthetic samples to balance class distribution.\n",
    "#6. from sklearn.naive_bayes import MultinomialNB: This line imports the Multinomial Naive Bayes classifier. It’s commonly used for text classification tasks.\n",
    "#7. from sklearn.linear_model import LogisticRegression: Logistic Regression is a linear model used for binary and multiclass classification. It estimates the probability of a binary outcome.\n",
    "#8. from sklearn.ensemble import RandomForestClassifier: The Random Forest classifier is an ensemble method that combines multiple decision trees to improve predictive accuracy.\n",
    "#9. from sklearn.svm import SVC: The Support Vector Machine (SVM) classifier is used for both classification and regression tasks. It finds the best hyperplane that separates data points into different classes.\n",
    "#10. from sklearn.neighbors import KNeighborsClassifier: The K-Nearest Neighbors (KNN) classifier assigns a class label based on the majority class among its k nearest neighbors.\n",
    "#11. import nltk: The Natural Language Toolkit (NLTK) is a library for natural language processing. It provides tools for text analysis, tokenization, stemming, and more\n",
    "#12. import re: The re module is used for regular expressions. It allows you to work with patterns in strings.\n",
    "#13. from nltk.corpus import stopwords: NLTK provides a list of common stopwords (words like “the,” “and,” “is,” etc.) that are often removed during text preprocessing.\n",
    "#14. from nltk.stem import PorterStemmer, WordNetLemmatizer: These are text normalization techniques:\n",
    "       # a) PorterStemmer: Reduces words to their root form (e.g., “running” becomes “run”).\n",
    "       # b) WordNetLemmatizer: Similar to stemming but produces valid words (e.g., “better” becomes “good”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0f7ca6-0288-494c-be3d-e0e43a341df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f1bdad-5682-4a37-97da-820a1824987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV\n",
    "data = pd.read_csv('Emotions_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb937b-bcff-4a91-8556-d502c9d8954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing is a crucial step in natural language processing (NLP) that involves cleaning and transforming unstructured text data to prepare it for analysis.\n",
    "   # a) Lowercasing\n",
    "   # b) Remove links\n",
    "   # c) Remove next line\n",
    "   # d) Remove words containing numbers\n",
    "   # e) Remove extra spaces\n",
    "   # f) Remove special characters\n",
    "   # g) Remove stop words\n",
    "   # h) Stemming\n",
    "   # i) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b178b8e-44e3-43f7-88c5-0d645c09ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lower Case\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove links\n",
    "    text = re.sub(r'\\n', ' ', text)  # Remove next lines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stop words\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])  # Stemming\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])  # Lemmatization\n",
    "    \n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ca12e-83b5-4551-a234-c4fcb6ccdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering refers to the process of creating new features (variables) from existing data or transforming existing features to improve the performance of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c182fca-ec1c-48c5-9971-ca269b1e79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "211d2f61-7bbd-43c5-a09c-8a138091b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4696981c-4755-4ba6-97e2-3de9fea46ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Validation Split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.333, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d07383af-e1e6-4bb3-b574-90a90ad18c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building and Evaluation\n",
    "def build_and_evaluate_model(model, param_grid):\n",
    "    # Grid Search for Hyperparameter Tuning\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(\"Training Classification Report:\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Validation Classification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"Confusion Matrix on Test Set:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    return best_model, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3634bf-7928-41c3-b95e-15f20b8ba9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  Multinomial Naive Bayes\n",
    "#2.  LogisticRegression\n",
    "#3.  RandomForestClassifier\n",
    "#4.  support vector classifier\n",
    "#5.  KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "112ffd2c-98ab-4ad8-8af2-b028c048bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultinomialNB\n",
      "Best Parameters: {'alpha': 1}\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      3716\n",
      "           1       0.95      0.88      0.91      3753\n",
      "           2       0.93      0.97      0.95      3752\n",
      "           3       0.95      0.95      0.95      3752\n",
      "           4       0.95      0.93      0.94      3763\n",
      "           5       0.92      1.00      0.96      3784\n",
      "\n",
      "    accuracy                           0.94     22520\n",
      "   macro avg       0.94      0.94      0.94     22520\n",
      "weighted avg       0.94      0.94      0.94     22520\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      1088\n",
      "           1       0.89      0.82      0.85      1089\n",
      "           2       0.89      0.95      0.92      1087\n",
      "           3       0.92      0.92      0.92      1050\n",
      "           4       0.93      0.90      0.92      1059\n",
      "           5       0.90      0.99      0.94      1064\n",
      "\n",
      "    accuracy                           0.91      6437\n",
      "   macro avg       0.91      0.91      0.91      6437\n",
      "weighted avg       0.91      0.91      0.91      6437\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       558\n",
      "           1       0.88      0.80      0.84       520\n",
      "           2       0.86      0.95      0.90       523\n",
      "           3       0.94      0.94      0.94       560\n",
      "           4       0.93      0.88      0.90       540\n",
      "           5       0.89      0.99      0.94       514\n",
      "\n",
      "    accuracy                           0.90      3215\n",
      "   macro avg       0.90      0.90      0.90      3215\n",
      "weighted avg       0.90      0.90      0.90      3215\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[ 934   44   23   46   27   14]\n",
      " [  41  890   89   21   17   31]\n",
      " [   6   35 1035    6    3    2]\n",
      " [  28   18   10  969   19    6]\n",
      " [  10    8    7   11  957   66]\n",
      " [   3    1    0    0    4 1056]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Evaluating LogisticRegression\n",
      "Best Parameters: {'C': 10}\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3716\n",
      "           1       0.99      0.97      0.98      3753\n",
      "           2       0.98      1.00      0.99      3752\n",
      "           3       0.99      0.99      0.99      3752\n",
      "           4       0.99      0.98      0.99      3763\n",
      "           5       0.99      1.00      0.99      3784\n",
      "\n",
      "    accuracy                           0.99     22520\n",
      "   macro avg       0.99      0.99      0.99     22520\n",
      "weighted avg       0.99      0.99      0.99     22520\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      1088\n",
      "           1       0.92      0.89      0.91      1089\n",
      "           2       0.93      0.97      0.95      1087\n",
      "           3       0.95      0.96      0.95      1050\n",
      "           4       0.97      0.94      0.95      1059\n",
      "           5       0.96      0.99      0.97      1064\n",
      "\n",
      "    accuracy                           0.94      6437\n",
      "   macro avg       0.94      0.94      0.94      6437\n",
      "weighted avg       0.94      0.94      0.94      6437\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       558\n",
      "           1       0.90      0.89      0.90       520\n",
      "           2       0.92      0.97      0.95       523\n",
      "           3       0.96      0.97      0.97       560\n",
      "           4       0.97      0.93      0.95       540\n",
      "           5       0.95      1.00      0.97       514\n",
      "\n",
      "    accuracy                           0.94      3215\n",
      "   macro avg       0.94      0.94      0.94      3215\n",
      "weighted avg       0.94      0.94      0.94      3215\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[ 980   39   20   32   13    4]\n",
      " [  33  973   57    8    6   12]\n",
      " [   4   17 1059    3    3    1]\n",
      " [  25   10    2 1004    8    1]\n",
      " [   7   14    3   11  995   29]\n",
      " [   3    3    0    0    3 1055]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Evaluating RandomForestClassifier\n",
      "Best Parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85      3716\n",
      "           1       0.80      0.80      0.80      3753\n",
      "           2       0.87      0.97      0.92      3752\n",
      "           3       0.95      0.93      0.94      3752\n",
      "           4       0.96      0.87      0.92      3763\n",
      "           5       0.91      1.00      0.95      3784\n",
      "\n",
      "    accuracy                           0.90     22520\n",
      "   macro avg       0.90      0.90      0.90     22520\n",
      "weighted avg       0.90      0.90      0.90     22520\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78      1088\n",
      "           1       0.75      0.76      0.75      1089\n",
      "           2       0.84      0.95      0.89      1087\n",
      "           3       0.91      0.90      0.91      1050\n",
      "           4       0.94      0.83      0.88      1059\n",
      "           5       0.89      1.00      0.94      1064\n",
      "\n",
      "    accuracy                           0.86      6437\n",
      "   macro avg       0.86      0.86      0.86      6437\n",
      "weighted avg       0.86      0.86      0.86      6437\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79       558\n",
      "           1       0.72      0.73      0.72       520\n",
      "           2       0.82      0.95      0.88       523\n",
      "           3       0.92      0.90      0.91       560\n",
      "           4       0.93      0.81      0.86       540\n",
      "           5       0.86      0.99      0.92       514\n",
      "\n",
      "    accuracy                           0.85      3215\n",
      "   macro avg       0.85      0.85      0.85      3215\n",
      "weighted avg       0.85      0.85      0.85      3215\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[ 790  160   51   49   26   12]\n",
      " [  97  824  110   22   12   24]\n",
      " [   7   34 1036    2    4    4]\n",
      " [  23   44   18  948   16    1]\n",
      " [  16   36   14   19  884   90]\n",
      " [   1    2    0    0    2 1059]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Evaluating SVC\n",
      "Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3716\n",
      "           1       1.00      1.00      1.00      3753\n",
      "           2       1.00      1.00      1.00      3752\n",
      "           3       1.00      1.00      1.00      3752\n",
      "           4       1.00      1.00      1.00      3763\n",
      "           5       1.00      1.00      1.00      3784\n",
      "\n",
      "    accuracy                           1.00     22520\n",
      "   macro avg       1.00      1.00      1.00     22520\n",
      "weighted avg       1.00      1.00      1.00     22520\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      1088\n",
      "           1       0.84      0.94      0.88      1089\n",
      "           2       0.97      0.93      0.95      1087\n",
      "           3       0.97      0.93      0.95      1050\n",
      "           4       0.97      0.94      0.95      1059\n",
      "           5       0.98      0.99      0.98      1064\n",
      "\n",
      "    accuracy                           0.94      6437\n",
      "   macro avg       0.94      0.94      0.94      6437\n",
      "weighted avg       0.94      0.94      0.94      6437\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       558\n",
      "           1       0.83      0.95      0.89       520\n",
      "           2       0.97      0.93      0.95       523\n",
      "           3       0.99      0.94      0.96       560\n",
      "           4       0.97      0.94      0.95       540\n",
      "           5       0.99      0.99      0.99       514\n",
      "\n",
      "    accuracy                           0.94      3215\n",
      "   macro avg       0.95      0.94      0.94      3215\n",
      "weighted avg       0.95      0.94      0.94      3215\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[ 987   59    6   23   10    3]\n",
      " [  28 1020   25    6    4    6]\n",
      " [   6   68 1011    0    1    1]\n",
      " [  29   32    0  981    8    0]\n",
      " [  15   33    1    3  991   16]\n",
      " [   3    6    0    0    4 1051]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Evaluating KNeighborsClassifier\n",
      "Best Parameters: {'n_neighbors': 3}\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      3716\n",
      "           1       0.99      0.58      0.73      3753\n",
      "           2       0.82      1.00      0.90      3752\n",
      "           3       0.92      0.98      0.95      3752\n",
      "           4       0.92      0.98      0.95      3763\n",
      "           5       0.91      1.00      0.95      3784\n",
      "\n",
      "    accuracy                           0.90     22520\n",
      "   macro avg       0.91      0.90      0.89     22520\n",
      "weighted avg       0.91      0.90      0.89     22520\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79      1088\n",
      "           1       0.96      0.34      0.50      1089\n",
      "           2       0.70      0.99      0.82      1087\n",
      "           3       0.85      0.95      0.90      1050\n",
      "           4       0.85      0.94      0.90      1059\n",
      "           5       0.83      1.00      0.91      1064\n",
      "\n",
      "    accuracy                           0.82      6437\n",
      "   macro avg       0.84      0.82      0.80      6437\n",
      "weighted avg       0.84      0.82      0.80      6437\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.79       558\n",
      "           1       0.96      0.35      0.51       520\n",
      "           2       0.70      0.99      0.82       523\n",
      "           3       0.85      0.95      0.90       560\n",
      "           4       0.86      0.93      0.89       540\n",
      "           5       0.84      1.00      0.91       514\n",
      "\n",
      "    accuracy                           0.83      3215\n",
      "   macro avg       0.85      0.83      0.81      3215\n",
      "weighted avg       0.85      0.83      0.81      3215\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[ 778    9   92   86   66   57]\n",
      " [ 102  371  342   76   82  116]\n",
      " [   0    3 1080    2    1    1]\n",
      " [  11    3   16  996   18    6]\n",
      " [   3    1   13   10 1000   32]\n",
      " [   0    0    0    0    3 1061]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Final Model Selected based on Validation Performance:\n",
      "LogisticRegression(C=10, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "# Define models and hyperparameters\n",
    "models = [\n",
    "    (MultinomialNB(), {'alpha': [0.01, 0.1, 1]}),\n",
    "    (LogisticRegression(max_iter=1000), {'C': [0.1, 1, 10]}),\n",
    "    (RandomForestClassifier(), {'n_estimators': [50, 100], 'max_depth': [10, 20]}),\n",
    "    (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}),\n",
    "    (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7]})\n",
    "]\n",
    "\n",
    "best_models = []\n",
    "best_accuracy = 0\n",
    "final_model = None\n",
    "\n",
    "for model, param_grid in models:\n",
    "    print(f\"Evaluating {model.__class__.__name__}\")\n",
    "    best_model, val_accuracy = build_and_evaluate_model(model, param_grid)\n",
    "    best_models.append((best_model, val_accuracy))\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        final_model = best_model\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Final Model Selected based on Validation Performance:\")\n",
    "print(final_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
