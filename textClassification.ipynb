{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c98e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "import re\n",
    "from math import ceil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde11962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "textData = pd.read_csv(\"Emotions_training.csv\")\n",
    "\n",
    "# showing data \n",
    "textData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1648d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  object\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "textData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92510c79",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531c147",
   "metadata": {},
   "source": [
    "Text column fits to be a **string** datatype which will enable us to perform string operations if needed in future for any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38c51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  string\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 250.1 KB\n"
     ]
    }
   ],
   "source": [
    "string_colms = {'text':'string'}\n",
    "textData = textData.astype(string_colms)\n",
    "textData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5551fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.565937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.501430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  16000.000000\n",
       "mean       1.565937\n",
       "std        1.501430\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a26f8",
   "metadata": {},
   "source": [
    "As we see maximum integer value in **label** colume is **5** so **int8** datatype will be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db8ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  string\n",
      " 1   label   16000 non-null  int8  \n",
      "dtypes: int8(1), string(1)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "#converting datatype for the int column\n",
    "textData['label'] = textData['label'].astype('int8')\n",
    "textData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c91cb4",
   "metadata": {},
   "source": [
    "So,now datatype is fixed.\n",
    "\n",
    "Moving further, there are certain required pre-rpocessing asked to be done in this project. These are as mentioned below : \n",
    "- Covert to Lower Case\n",
    "- Remove links\n",
    "- Remove next lines (\\n)\n",
    "- Remove Words containing numbers\n",
    "- Remove Extra spaces\n",
    "- Remove Special characters\n",
    "\n",
    "While perfoming above data-perprocessing the impact was not clearly visible as we did not know what rows are getting refactored. So,firstly let's check upon the impact of performing these on the rows of dataset we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968f7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Find if upper case exists to be converted to lower case\n",
    "rowsWithCapitalLetters = textData[textData['text'].str.islower() == False].shape[0]\n",
    "\n",
    "# Find rows with links to be removed\n",
    "rowsWithLinks = textData[textData['text'].str.contains(r'https?://[^\\s]+')].shape[0]\n",
    "\n",
    "# Find rows with newlines to be removed\n",
    "rowsWithNewLine = textData[textData['text'].str.contains('\\n')].shape[0]\n",
    "\n",
    "# Find rows with special characters to be removed\n",
    "def has_special_chars(text):\n",
    "    for char in text:\n",
    "        if not char.isalnum() and char not in [' ']: # It can also be new line but its zero as well :)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rowsWithSpChar = textData[textData['text'].apply(has_special_chars)].shape[0]\n",
    "\n",
    "# Find rows with alphanumeric characters to be removed\n",
    "def has_alnum(text):\n",
    "    for char in text:\n",
    "        if char.isnumeric():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rowsWithNum = textData[textData['text'].apply(has_alnum)].shape[0]\n",
    "\n",
    "# Find rows with extra spaces to be removed\n",
    "def has_extra_spaces(text):\n",
    "    return '  ' in text\n",
    "\n",
    "rowsWithExSpc = textData[textData['text'].apply(has_extra_spaces)].shape[0]\n",
    "\n",
    "print(rowsWithCapitalLetters, \n",
    "      rowsWithLinks, \n",
    "      rowsWithNewLine, \n",
    "      rowsWithSpChar, \n",
    "      rowsWithNum, \n",
    "      rowsWithExSpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a9961",
   "metadata": {},
   "source": [
    "For the checks mentioned for the pre-processing, all the impacted rows were extracted into their respective dataframes and looked upon the count of rows impacted. Surprisingly, none of the rows had anything that would be altered even if these pre-processing steps were performed.\n",
    "Therefore it is concluded that these pre-processing steps would have no change on the dataset.\n",
    "\n",
    "However, while performing these, it was found that the text data has random words, weird songs, html tags, etc inserted to many of the sentences in text column making our data noisy. Below is one of the example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c8be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>i feel they are pretty safe on my blog img src...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>i stopped feeling so exhausted a href http pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>i feel so dazed a href http twitter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>i feel unwelcome at work sometimes and think p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>i a href http feeling groggy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "125  i feel they are pretty safe on my blog img src...      1\n",
       "323  i stopped feeling so exhausted a href http pro...      0\n",
       "462                i feel so dazed a href http twitter      5\n",
       "866  i feel unwelcome at work sometimes and think p...      0\n",
       "967                       i a href http feeling groggy      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding occurance of random word in dataset\n",
    "randomWords = textData[textData['text'].str.contains('http')] #https, href, a href http, www, etc\n",
    "print(randomWords.shape)\n",
    "randomWords.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45927e3d",
   "metadata": {},
   "source": [
    "So, an attempt is being made to find and get rid of as much noise as possible by removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dab0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the substrings to remove\n",
    "remove_strings = [' a href http ', ' http ', ' https ', ' www ', ' href ', ' src ', ' img ', ' s ']\n",
    "\n",
    "# Iterate through each substring and remove it from the 'text' column in the main DataFrame\n",
    "for substring in remove_strings:\n",
    "    textData['text'] = textData['text'].str.replace(substring, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf914a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>i definitely feel like hot stuff strutting dow...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>i do not know how to feel my hearts aching sad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>i am feeling so festive right now and not just...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>im feeling my loving heart is all yours for th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>im feeling determined to face facts have a gan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1531  i definitely feel like hot stuff strutting dow...      2\n",
       "2263  i do not know how to feel my hearts aching sad...      0\n",
       "3170  i am feeling so festive right now and not just...      1\n",
       "3231  im feeling my loving heart is all yours for th...      2\n",
       "4986  im feeling determined to face facts have a gan...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if it is removed for one as example\n",
    "randomWords = textData[textData['text'].str.contains('http')] #http, href, a href http, www, etc\n",
    "print(randomWords.shape)\n",
    "randomWords.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086544c",
   "metadata": {},
   "source": [
    "#### Question : \n",
    "Above is not scalable way. How can we deal with such a scenerio efficiently ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166d79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "textData['text'] = textData['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "textData['text'] = textData['text'].astype('string') # as above operation changes it to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa55f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "stemmer = PorterStemmer()\n",
    "textData['text'] = textData['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d214ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "textData['text'] = textData['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "textData['text'] = textData['text'].astype('string') # as above operation changes it to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "effdfa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  string\n",
      " 1   label   16000 non-null  int8  \n",
      "dtypes: int8(1), string(1)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "textData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2c04b",
   "metadata": {},
   "source": [
    "So we have completed with data-preprocessing.As we can see that before data-preprocessing the memory usage was **250.1+ KB** and after data-preprocessing the memory usage is **140.8 KB** it clearly show that memory usage is **reduced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6e66b",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "\n",
    "Another important thing to make sure before feeding our data into the model is the class distribution of the data. In our case where the expected class are divided into six outcomes, 0 to 5, an equal class distribution can be considered ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3d7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67992f",
   "metadata": {},
   "source": [
    "conclude above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9c9c8",
   "metadata": {},
   "source": [
    "### Vectorization Of Text  Data\n",
    "- Vectorization is essential for text classification tasks because machine learning algorithms typically require numerical input data. \n",
    "- Text data, being categorical and unstructured, needs to be converted into a numerical format that algorithms can process effectively. \n",
    "- Vectorization transforms text into numerical features, allowing machine learning models to learn patterns and make predictions based on the text's content. \n",
    "\n",
    "Which ? Wh ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe68a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaand</th>\n",
       "      <th>aaaaand</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aac</th>\n",
       "      <th>aahhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonisamid</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zq</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zum</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15603</th>\n",
       "      <td>im psych stop that kind good thing wont feel p...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>also feel stubborn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12961</th>\n",
       "      <td>feel pretti cranki could think much better fee...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>think lot time woman perceiv problem husband a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12732</th>\n",
       "      <td>feel like cold feel sick</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label   aa  \\\n",
       "15603  im psych stop that kind good thing wont feel p...      4  0.0   \n",
       "2691                                  also feel stubborn      3  0.0   \n",
       "12961  feel pretti cranki could think much better fee...      3  0.0   \n",
       "13756  think lot time woman perceiv problem husband a...      1  0.0   \n",
       "12732                           feel like cold feel sick      3  0.0   \n",
       "\n",
       "       aaaaaaand  aaaaand  aaaand  aac  aahhh  aaron   ab  ...  zombi  zone  \\\n",
       "15603        0.0      0.0     0.0  0.0    0.0    0.0  0.0  ...    0.0   0.0   \n",
       "2691         0.0      0.0     0.0  0.0    0.0    0.0  0.0  ...    0.0   0.0   \n",
       "12961        0.0      0.0     0.0  0.0    0.0    0.0  0.0  ...    0.0   0.0   \n",
       "13756        0.0      0.0     0.0  0.0    0.0    0.0  0.0  ...    0.0   0.0   \n",
       "12732        0.0      0.0     0.0  0.0    0.0    0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "       zonisamid  zoo  zoom   zq  zucchini  zum  zumba   zz  \n",
       "15603        0.0  0.0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
       "2691         0.0  0.0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
       "12961        0.0  0.0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
       "13756        0.0  0.0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
       "12732        0.0  0.0   0.0  0.0       0.0  0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 10326 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the 'text' column to generate TF-IDF features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(textData['text'])\n",
    "\n",
    "# Convert TF-IDF features to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the TF-IDF DataFrame with the original DataFrame\n",
    "textData = pd.concat([textData, tfidf_df], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "textData.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d80d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
