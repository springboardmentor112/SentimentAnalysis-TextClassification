{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47be24ff-1a7a-496e-a902-fd6e33bec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014f2dbd-33dd-4eb7-9deb-611c2308f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158848a2-3d41-4edc-8534-17fbcf3288c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4028a7ef-1451-4770-a364-1027285a1d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41d57162-5adf-4e50-a6a8-a742a7203da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the set of stopwords from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df335f52-60ff-4499-bdfb-4d912b3ad3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a859b4-671c-4889-a8fe-98322061e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fa6df1-9bab-41dd-b80d-19b36626fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Emotions_training.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2a8db8-b1a2-4cc6-9369-6a1416ffbe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ace7fb9b-a690-4a90-b939-28cef93e5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ive been taking or milligrams or times recomme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i feel as confused about life as a teenager or...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i have been with petronas for years i feel tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i feel romantic too</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3\n",
       "5  ive been feeling a little burdened lately wasn...      0\n",
       "6  ive been taking or milligrams or times recomme...      5\n",
       "7  i feel as confused about life as a teenager or...      4\n",
       "8  i have been with petronas for years i feel tha...      1\n",
       "9                                i feel romantic too      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6ad86-b6dc-4add-8423-5243e91a9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "683f2952-8889-4f04-a832-eb0e63741be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                i didnt feel humiliated      0\n",
       "1      i can go from feeling so hopeless to so damned...      0\n",
       "2       im grabbing a minute to post i feel greedy wrong      3\n",
       "3      i am ever feeling nostalgic about the fireplac...      2\n",
       "4                                   i am feeling grouchy      3\n",
       "...                                                  ...    ...\n",
       "15995  i just had a very brief time in the beanbag an...      0\n",
       "15996  i am now turning and i feel pathetic that i am...      0\n",
       "15997                     i feel strong and good overall      1\n",
       "15998  i feel like this was such a rude comment and i...      3\n",
       "15999  i know a lot but i feel so stupid because i ca...      0\n",
       "\n",
       "[15999 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eca970-b315-4bae-ae6f-c479e216a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## about data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9a833c-3f88-4c9c-844f-0619a3ab04bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  object\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77eef93c-f72b-4e3b-86b1-feb2e7160bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the upper case in text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d583fc-7041-46c0-b7af-2f190eeaeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "entirely_uppercase_names = df[df['text'].str.isupper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8075649f-e9fc-451b-ad90-7ad38c662c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(entirely_uppercase_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012669ae-3d35-4783-acfa-5b346f8ce564",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check null value in data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2078caf6-4df3-4497-b91c-7867acb92940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "null_name_rows = df[df['text'].isnull()]\n",
    "print(null_name_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204af717-3930-47ef-9be1-879923dc351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove next line  in the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d38cd0-fd63-45e9-826e-4ebb8edb188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\n', ' ', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b848a5fb-fa4c-47e4-974e-5494194e9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e482b131-888c-42c2-8bbe-1fde437fb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the link in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f0bcffd-b92c-4dd9-bbf0-52fbf6467f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = r'https?://\\S+|www\\.\\S+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00564109-9b8f-4596-88c8-0a399181e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(url_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99ebf87-82c6-4840-8b0c-0fecddce1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n",
      "5  ive been feeling a little burdened lately wasn...      0\n",
      "6  ive been taking or milligrams or times recomme...      5\n",
      "7  i feel as confused about life as a teenager or...      4\n",
      "8  i have been with petronas for years i feel tha...      1\n",
      "9                                i feel romantic too      2\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9aec9a1-868b-4058-a9bd-415491242333",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove extra spaces between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d6faec-09e5-4d45-821b-6236e5195cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.strip()  \n",
    "df['text'] = df['text'].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "251b58b8-66ca-414c-92b6-d81d639eb342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n",
      "5  ive been feeling a little burdened lately wasn...      0\n",
      "6  ive been taking or milligrams or times recomme...      5\n",
      "7  i feel as confused about life as a teenager or...      4\n",
      "8  i have been with petronas for years i feel tha...      1\n",
      "9                                i feel romantic too      2\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c66925e2-e916-4531-84a5-84c32442f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  find the special characters in a text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b1e0f7-87bd-4b15-8da2-cb1df7792798",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_pattern = r'[^a-zA-Z0-9\\s,\\.!?;:]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d78bbe37-c82f-4977-a7af-7ff8aa49d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_special_char'] = df['text'].str.contains(special_char_pattern, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93ad3920-de0c-4789-a2c9-d400680d9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_special_chars = df[df['has_special_char'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb2180e9-5406-46fd-8feb-52e2c8bae354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label, has_special_char, text_column_no_stopwords]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e66f4fc1-caab-40cf-a147-e15fa254d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing stopwords from a text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78b3ef4d-39b4-400b-a0f0-8a8429980e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    return ' '.join(filtered_words)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['text_column_no_stopwords'] = df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "214fdd0a-08b1-4a8d-b673-b530575ac4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                            i didnt feel humiliated   \n",
      "1  i can go from feeling so hopeless to so damned...   \n",
      "2   im grabbing a minute to post i feel greedy wrong   \n",
      "3  i am ever feeling nostalgic about the fireplac...   \n",
      "4                               i am feeling grouchy   \n",
      "5  ive been feeling a little burdened lately wasn...   \n",
      "6  ive been taking or milligrams or times recomme...   \n",
      "7  i feel as confused about life as a teenager or...   \n",
      "8  i have been with petronas for years i feel tha...   \n",
      "9                                i feel romantic too   \n",
      "\n",
      "                            text_column_no_stopwords  \n",
      "0                              didnt feel humiliated  \n",
      "1  go feeling hopeless damned hopeful around some...  \n",
      "2          im grabbing minute post feel greedy wrong  \n",
      "3  ever feeling nostalgic fireplace know still pr...  \n",
      "4                                    feeling grouchy  \n",
      "5      ive feeling little burdened lately wasnt sure  \n",
      "6  ive taking milligrams times recommended amount...  \n",
      "7     feel confused life teenager jaded year old man  \n",
      "8  petronas years feel petronas performed well ma...  \n",
      "9                                      feel romantic  \n"
     ]
    }
   ],
   "source": [
    "print(df[['text', 'text_column_no_stopwords']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eb5a3e7-7965-47cb-a6f3-d34258570eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fbe6d-8f3a-4df1-933f-dbf647eda78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-process and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31ff2c90-6a90-40d8-922f-de7607a274eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_optimized(text, stop_words):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c0fa85e-f737-4987-8c33-4db9c90dd23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vikash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "    text = text.lower()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05342de1-5cce-4eba-8638-165abaf01597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d011af25-af0f-4dd4-9615-089046c3ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_column_no_stopwords'] = df['text'].apply(lambda x: remove_stopwords_optimized(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2d642-59a7-4b6f-8957-d3cb96449ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making department  of the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d9a5647-ba59-4584-9704-54eb83781704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['cleaned_text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4a20d1b-a298-4518-a9fb-9f35b51e14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['cleaned_text'].apply(len)\n",
    "df['word_count'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "524880d7-5e55-4c8c-a06e-663cda2434fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>has_special_char</th>\n",
       "      <th>text_column_no_stopwords</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>[didnt, feel, humiliated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>[im, grabbing, minute, post, feel, greedy, wrong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>[feeling, grouchy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>i feel like throwing away the shitty piece of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>feel like throwing away shitty piece shit paper</td>\n",
       "      <td>feel like throwing away shitty piece shit paper</td>\n",
       "      <td>[feel, like, throwing, away, shitty, piece, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>im starting to feel wryly amused at the banal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>im starting feel wryly amused banal comedy err...</td>\n",
       "      <td>im starting feel wryly amused banal comedy err...</td>\n",
       "      <td>[im, starting, feel, wryly, amused, banal, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>i find every body beautiful and only want peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>find every body beautiful want people feel vit...</td>\n",
       "      <td>find every body beautiful want people feel vit...</td>\n",
       "      <td>[find, every, body, beautiful, want, people, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>i hear are owners who feel victimized by their...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>hear owners feel victimized associations assoc...</td>\n",
       "      <td>hear owner feel victimized association associa...</td>\n",
       "      <td>[hear, owner, feel, victimized, association, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i say goodbye to the fam theyre all sad a cryi...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>say goodbye fam theyre sad crying feel like he...</td>\n",
       "      <td>say goodbye fam theyre sad cry feel like heart...</td>\n",
       "      <td>[say, goodbye, fam, theyre, sad, cry, feel, li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  \\\n",
       "0                             i didnt feel humiliated      0   \n",
       "1   i can go from feeling so hopeless to so damned...      0   \n",
       "2    im grabbing a minute to post i feel greedy wrong      3   \n",
       "3   i am ever feeling nostalgic about the fireplac...      2   \n",
       "4                                i am feeling grouchy      3   \n",
       "..                                                ...    ...   \n",
       "95  i feel like throwing away the shitty piece of ...      0   \n",
       "96  im starting to feel wryly amused at the banal ...      1   \n",
       "97  i find every body beautiful and only want peop...      1   \n",
       "98  i hear are owners who feel victimized by their...      0   \n",
       "99  i say goodbye to the fam theyre all sad a cryi...      3   \n",
       "\n",
       "    has_special_char                           text_column_no_stopwords  \\\n",
       "0              False                              didnt feel humiliated   \n",
       "1              False  go feeling hopeless damned hopeful around some...   \n",
       "2              False          im grabbing minute post feel greedy wrong   \n",
       "3              False  ever feeling nostalgic fireplace know still pr...   \n",
       "4              False                                    feeling grouchy   \n",
       "..               ...                                                ...   \n",
       "95             False    feel like throwing away shitty piece shit paper   \n",
       "96             False  im starting feel wryly amused banal comedy err...   \n",
       "97             False  find every body beautiful want people feel vit...   \n",
       "98             False  hear owners feel victimized associations assoc...   \n",
       "99             False  say goodbye fam theyre sad crying feel like he...   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "0                               didnt feel humiliated   \n",
       "1   go feeling hopeless damned hopeful around some...   \n",
       "2           im grabbing minute post feel greedy wrong   \n",
       "3   ever feeling nostalgic fireplace know still pr...   \n",
       "4                                     feeling grouchy   \n",
       "..                                                ...   \n",
       "95    feel like throwing away shitty piece shit paper   \n",
       "96  im starting feel wryly amused banal comedy err...   \n",
       "97  find every body beautiful want people feel vit...   \n",
       "98  hear owner feel victimized association associa...   \n",
       "99  say goodbye fam theyre sad cry feel like heart...   \n",
       "\n",
       "                                               tokens  \n",
       "0                           [didnt, feel, humiliated]  \n",
       "1   [go, feeling, hopeless, damned, hopeful, aroun...  \n",
       "2   [im, grabbing, minute, post, feel, greedy, wrong]  \n",
       "3   [ever, feeling, nostalgic, fireplace, know, st...  \n",
       "4                                  [feeling, grouchy]  \n",
       "..                                                ...  \n",
       "95  [feel, like, throwing, away, shitty, piece, sh...  \n",
       "96  [im, starting, feel, wryly, amused, banal, com...  \n",
       "97  [find, every, body, beautiful, want, people, f...  \n",
       "98  [hear, owner, feel, victimized, association, a...  \n",
       "99  [say, goodbye, fam, theyre, sad, cry, feel, li...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a69c7-4d2c-4186-aacd-d2c0c0a184ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lemmatization on the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7cf86b8-4d90-495d-ae02-f1423f56d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1121c32-e204-44d2-af6e-4778bb4160f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to convert nltk tag to wordnet tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Example usage\n",
    "df['lemmatized_text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9f9fe-9ec8-4a4a-bc1c-015fd1bcb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "all pre -process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c2f1141-bd56-4cd0-a690-81d49ac444aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)\n",
    "df['lemmatized_text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3811d598-6f6b-4f91-b67e-119bfeef6325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                            i didnt feel humiliated   \n",
      "1  i can go from feeling so hopeless to so damned...   \n",
      "2   im grabbing a minute to post i feel greedy wrong   \n",
      "3  i am ever feeling nostalgic about the fireplac...   \n",
      "4                               i am feeling grouchy   \n",
      "\n",
      "                                     lemmatized_text  \n",
      "0                             i didnt feel humiliate  \n",
      "1  i can go from feel so hopeless to so damn hope...  \n",
      "2       im grab a minute to post i feel greedy wrong  \n",
      "3  i be ever feel nostalgic about the fireplace i...  \n",
      "4                                  i be feel grouchy  \n"
     ]
    }
   ],
   "source": [
    "print(df[['text', 'lemmatized_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0be24a-5244-42e7-9177-a77432b44c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  after complete the all data pre-process final data download  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a15535e-3b37-4708-971c-30de72ebf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_Emotions_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898133bc-688c-4f84-97d3-62a83fa24514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
