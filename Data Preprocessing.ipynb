{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2354a3c1",
   "metadata": {},
   "source": [
    "# Imported required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb2e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e732a0",
   "metadata": {},
   "source": [
    "## Downloaded NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a5190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sumit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sumit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sumit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada78ed8",
   "metadata": {},
   "source": [
    "## Loaded The Dataset And Printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e8ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               reviewId       userName  \\\n",
      "0  0197c118-5c6f-4a7b-894c-970023d1a350        Mar Zur   \n",
      "1  94868fb5-a21d-4ef9-ab85-81b2ed3d0785   Devin Rivera   \n",
      "2  825da34e-f65d-4ef3-991d-02d5291820d6  Heidi Kinsley   \n",
      "3  a49c2875-651a-4c33-b79c-5813780d659e  Daniel Keller   \n",
      "4  9482c75e-2e63-46ab-8c94-47273dd6a829  A Google user   \n",
      "\n",
      "                                           userImage  \\\n",
      "0  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "3  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
      "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
      "\n",
      "                                             content  thumbsUpCount  \\\n",
      "0  I have the same recurring tasks to do every da...             11   \n",
      "1  Instead of shopping around, I downloaded Any.d...              8   \n",
      "2  Why does every once in a while... out of the b...              6   \n",
      "3  Terrible Update! This app used to be perfect f...              5   \n",
      "4  This app is deceivingly terrible. There are so...             20   \n",
      "\n",
      "  reviewCreatedVersion                at  \\\n",
      "0             4.16.6.2  22-07-2020 13:13   \n",
      "1                  NaN  08-12-2020 06:24   \n",
      "2             5.11.1.2  09-07-2021 13:51   \n",
      "3                  NaN  16-11-2020 01:50   \n",
      "4             4.14.0.4  31-01-2019 16:19   \n",
      "\n",
      "                                        replyContent         repliedAt  \\\n",
      "0  Our team will be happy to look into it for you...  23-07-2020 16:32   \n",
      "1  We are not aware of any issues with randomized...  10-12-2020 09:38   \n",
      "2  Sorry to hear that! It sounds like you might h...  11-07-2021 11:16   \n",
      "3  Please note that the tasks in your tasks view ...  17-11-2020 09:31   \n",
      "4  Hi Ryan, it sounds like you are describing our...  05-02-2019 11:52   \n",
      "\n",
      "  appVersion      sortOrder      appId  \n",
      "0   4.16.6.2  most_relevant  com.anydo  \n",
      "1        NaN  most_relevant  com.anydo  \n",
      "2   5.11.1.2  most_relevant  com.anydo  \n",
      "3        NaN  most_relevant  com.anydo  \n",
      "4   4.14.0.4  most_relevant  com.anydo  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fee2e3",
   "metadata": {},
   "source": [
    "## Converted The Content Into Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a9ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323742b6",
   "metadata": {},
   "source": [
    "##  Removed the Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4d6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].astype(str).apply(lambda x: re.sub(r'http\\S+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f118adf",
   "metadata": {},
   "source": [
    "## Removed next lines (\\n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74fc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2783304",
   "metadata": {},
   "source": [
    "## Removed the words that contains numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: re.sub(r'\\b\\w*\\d\\w*\\b', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a8494",
   "metadata": {},
   "source": [
    "## Removed the extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8869684",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f353666",
   "metadata": {},
   "source": [
    "## Removed the special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb9064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' \n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "data['content'] = data['content'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa126973",
   "metadata": {},
   "source": [
    "## Removed of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "952dfd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "data['content'] = data['content'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb9c74",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca5fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "data['content'] = data['content'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430db2f",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a3976c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "data['content'] = data['content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffdd37",
   "metadata": {},
   "source": [
    "## Printed the \"content\" data after implementing data preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "763952d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        recur task day need todolist remind buzz time ...\n",
      "1        instead shop download anydo wide set day sched...\n",
      "2        blue app ask updat acct email task list lost t...\n",
      "3        terribl updat app perfect plan certain task co...\n",
      "4        app deceivingli terribl nice design featur lik...\n",
      "                               ...                        \n",
      "16782                                            excel app\n",
      "16783    love easi use life organ love way photo locat ...\n",
      "16784                    love plan check app everyday love\n",
      "16785                                         exactli need\n",
      "16786                                                 good\n",
      "Name: content, Length: 16787, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c2835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
